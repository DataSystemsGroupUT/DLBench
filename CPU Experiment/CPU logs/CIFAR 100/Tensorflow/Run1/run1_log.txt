Loading data...
(50000, 32, 32, 3)
(50000,)
(10000, 32, 32, 3)
(10000,)
(?, 32, 32, 128)
(?, 30, 30, 128)
(?, 15, 15, 128)
(?, 15, 15, 256)
(?, 13, 13, 256)
(?, 6, 6, 256)
(?, 6, 6, 512)
(?, 4, 4, 512)
(?, 2, 2, 512)
Training
Iteration 0: with minibatch training loss = 4.62 and accuracy of 0.0078
Iteration 128: with minibatch training loss = 4.61 and accuracy of 0.023
Iteration 256: with minibatch training loss = 4.6 and accuracy of 0
Iteration 384: with minibatch training loss = 4.62 and accuracy of 0
Epoch 1, Train loss: 4.61 and Train accuracy of 0.00996, Test loss: 4.61 and Test accuracy of 0.0117
Iteration 512: with minibatch training loss = 4.6 and accuracy of 0.023
Iteration 640: with minibatch training loss = 4.62 and accuracy of 0.0078
Iteration 768: with minibatch training loss = 4.62 and accuracy of 0.023
Epoch 2, Train loss: 4.61 and Train accuracy of 0.0101, Test loss: 4.6 and Test accuracy of 0.0099
Iteration 896: with minibatch training loss = 4.6 and accuracy of 0.0078
Iteration 1024: with minibatch training loss = 4.59 and accuracy of 0.039
Iteration 1152: with minibatch training loss = 4.6 and accuracy of 0.0078
Epoch 3, Train loss: 4.6 and Train accuracy of 0.0116, Test loss: 4.59 and Test accuracy of 0.0177
Iteration 1280: with minibatch training loss = 4.58 and accuracy of 0.016
Iteration 1408: with minibatch training loss = 4.56 and accuracy of 0.031
Iteration 1536: with minibatch training loss = 4.51 and accuracy of 0.023
Epoch 4, Train loss: 4.57 and Train accuracy of 0.018, Test loss: 4.52 and Test accuracy of 0.0252
Iteration 1664: with minibatch training loss = 4.47 and accuracy of 0.016
Iteration 1792: with minibatch training loss = 4.48 and accuracy of 0.031
Iteration 1920: with minibatch training loss = 4.39 and accuracy of 0.047
Epoch 5, Train loss: 4.51 and Train accuracy of 0.0249, Test loss: 4.41 and Test accuracy of 0.0371
Iteration 2048: with minibatch training loss = 4.48 and accuracy of 0.0078
Iteration 2176: with minibatch training loss = 4.38 and accuracy of 0.031
Iteration 2304: with minibatch training loss = 4.46 and accuracy of 0.023
Epoch 6, Train loss: 4.4 and Train accuracy of 0.0316, Test loss: 4.25 and Test accuracy of 0.0535
Iteration 2432: with minibatch training loss = 4.38 and accuracy of 0.0078
Iteration 2560: with minibatch training loss = 4.2 and accuracy of 0.078
Iteration 2688: with minibatch training loss = 4.34 and accuracy of 0.039
Epoch 7, Train loss: 4.28 and Train accuracy of 0.0454, Test loss: 4.13 and Test accuracy of 0.0712
Iteration 2816: with minibatch training loss = 4.25 and accuracy of 0.031
Iteration 2944: with minibatch training loss = 4.33 and accuracy of 0.031
Iteration 3072: with minibatch training loss = 4.24 and accuracy of 0.047
Epoch 8, Train loss: 4.18 and Train accuracy of 0.0591, Test loss: 4.03 and Test accuracy of 0.0877
Iteration 3200: with minibatch training loss = 4.07 and accuracy of 0.07
Iteration 3328: with minibatch training loss = 3.98 and accuracy of 0.07
Iteration 3456: with minibatch training loss = 4 and accuracy of 0.086
Epoch 9, Train loss: 4.11 and Train accuracy of 0.0705, Test loss: 3.96 and Test accuracy of 0.0982
Iteration 3584: with minibatch training loss = 3.99 and accuracy of 0.1
Iteration 3712: with minibatch training loss = 3.95 and accuracy of 0.12
Iteration 3840: with minibatch training loss = 3.96 and accuracy of 0.078
Epoch 10, Train loss: 4.04 and Train accuracy of 0.0776, Test loss: 3.89 and Test accuracy of 0.11
Iteration 3968: with minibatch training loss = 4.01 and accuracy of 0.086
Iteration 4096: with minibatch training loss = 3.93 and accuracy of 0.062
Iteration 4224: with minibatch training loss = 3.85 and accuracy of 0.15
Epoch 11, Train loss: 3.98 and Train accuracy of 0.086, Test loss: 3.83 and Test accuracy of 0.118
Iteration 4352: with minibatch training loss = 3.96 and accuracy of 0.078
Iteration 4480: with minibatch training loss = 3.98 and accuracy of 0.07
Iteration 4608: with minibatch training loss = 3.73 and accuracy of 0.16
Epoch 12, Train loss: 3.92 and Train accuracy of 0.0951, Test loss: 3.76 and Test accuracy of 0.131
Iteration 4736: with minibatch training loss = 3.91 and accuracy of 0.12
Iteration 4864: with minibatch training loss = 3.88 and accuracy of 0.1
Iteration 4992: with minibatch training loss = 3.82 and accuracy of 0.11
Epoch 13, Train loss: 3.86 and Train accuracy of 0.103, Test loss: 3.71 and Test accuracy of 0.141
Iteration 5120: with minibatch training loss = 3.8 and accuracy of 0.11
Iteration 5248: with minibatch training loss = 3.87 and accuracy of 0.1
Iteration 5376: with minibatch training loss = 3.77 and accuracy of 0.12
Epoch 14, Train loss: 3.81 and Train accuracy of 0.112, Test loss: 3.66 and Test accuracy of 0.15
Iteration 5504: with minibatch training loss = 3.76 and accuracy of 0.12
Iteration 5632: with minibatch training loss = 3.57 and accuracy of 0.12
Iteration 5760: with minibatch training loss = 3.54 and accuracy of 0.14
Epoch 15, Train loss: 3.76 and Train accuracy of 0.122, Test loss: 3.61 and Test accuracy of 0.162
Iteration 5888: with minibatch training loss = 3.65 and accuracy of 0.1
Iteration 6016: with minibatch training loss = 3.73 and accuracy of 0.12
Iteration 6144: with minibatch training loss = 3.53 and accuracy of 0.1
Epoch 16, Train loss: 3.72 and Train accuracy of 0.127, Test loss: 3.56 and Test accuracy of 0.164
Iteration 6272: with minibatch training loss = 3.67 and accuracy of 0.13
Iteration 6400: with minibatch training loss = 3.84 and accuracy of 0.11
Iteration 6528: with minibatch training loss = 3.91 and accuracy of 0.1
Epoch 17, Train loss: 3.68 and Train accuracy of 0.133, Test loss: 3.52 and Test accuracy of 0.171
Iteration 6656: with minibatch training loss = 3.62 and accuracy of 0.16
Iteration 6784: with minibatch training loss = 3.77 and accuracy of 0.094
Iteration 6912: with minibatch training loss = 3.7 and accuracy of 0.15
Epoch 18, Train loss: 3.64 and Train accuracy of 0.141, Test loss: 3.48 and Test accuracy of 0.178
Iteration 7040: with minibatch training loss = 3.7 and accuracy of 0.12
Iteration 7168: with minibatch training loss = 3.42 and accuracy of 0.2
Iteration 7296: with minibatch training loss = 3.71 and accuracy of 0.086
Iteration 7424: with minibatch training loss = 3.61 and accuracy of 0.14
Epoch 19, Train loss: 3.6 and Train accuracy of 0.149, Test loss: 3.46 and Test accuracy of 0.185
Iteration 7552: with minibatch training loss = 3.6 and accuracy of 0.15
Iteration 7680: with minibatch training loss = 3.53 and accuracy of 0.16
Iteration 7808: with minibatch training loss = 3.58 and accuracy of 0.14
Epoch 20, Train loss: 3.56 and Train accuracy of 0.155, Test loss: 3.41 and Test accuracy of 0.19
Iteration 7936: with minibatch training loss = 3.5 and accuracy of 0.19
Iteration 8064: with minibatch training loss = 3.49 and accuracy of 0.16
Iteration 8192: with minibatch training loss = 3.65 and accuracy of 0.18
Epoch 21, Train loss: 3.53 and Train accuracy of 0.163, Test loss: 3.36 and Test accuracy of 0.2
Iteration 8320: with minibatch training loss = 3.53 and accuracy of 0.18
Iteration 8448: with minibatch training loss = 3.44 and accuracy of 0.13
Iteration 8576: with minibatch training loss = 3.43 and accuracy of 0.18
Epoch 22, Train loss: 3.49 and Train accuracy of 0.169, Test loss: 3.32 and Test accuracy of 0.207
Iteration 8704: with minibatch training loss = 3.4 and accuracy of 0.15
Iteration 8832: with minibatch training loss = 3.61 and accuracy of 0.18
Iteration 8960: with minibatch training loss = 3.45 and accuracy of 0.17
Epoch 23, Train loss: 3.45 and Train accuracy of 0.178, Test loss: 3.29 and Test accuracy of 0.214
Iteration 9088: with minibatch training loss = 3.35 and accuracy of 0.17
Iteration 9216: with minibatch training loss = 3.49 and accuracy of 0.2
Iteration 9344: with minibatch training loss = 3.25 and accuracy of 0.26
Epoch 24, Train loss: 3.41 and Train accuracy of 0.183, Test loss: 3.25 and Test accuracy of 0.222
Iteration 9472: with minibatch training loss = 3.42 and accuracy of 0.22
Iteration 9600: with minibatch training loss = 3.32 and accuracy of 0.19
Iteration 9728: with minibatch training loss = 3.5 and accuracy of 0.18
Epoch 25, Train loss: 3.38 and Train accuracy of 0.19, Test loss: 3.22 and Test accuracy of 0.225
Iteration 9856: with minibatch training loss = 3.47 and accuracy of 0.16
Iteration 9984: with minibatch training loss = 3.44 and accuracy of 0.15
Iteration 10112: with minibatch training loss = 3.25 and accuracy of 0.2
Epoch 26, Train loss: 3.34 and Train accuracy of 0.196, Test loss: 3.19 and Test accuracy of 0.236
Iteration 10240: with minibatch training loss = 3.5 and accuracy of 0.13
Iteration 10368: with minibatch training loss = 3.15 and accuracy of 0.24
Iteration 10496: with minibatch training loss = 3.23 and accuracy of 0.2
Epoch 27, Train loss: 3.31 and Train accuracy of 0.205, Test loss: 3.15 and Test accuracy of 0.243
Iteration 10624: with minibatch training loss = 3.17 and accuracy of 0.2
Iteration 10752: with minibatch training loss = 3.11 and accuracy of 0.23
Iteration 10880: with minibatch training loss = 2.95 and accuracy of 0.3
Epoch 28, Train loss: 3.27 and Train accuracy of 0.208, Test loss: 3.12 and Test accuracy of 0.248
Iteration 11008: with minibatch training loss = 3.39 and accuracy of 0.2
Iteration 11136: with minibatch training loss = 3.3 and accuracy of 0.22
Iteration 11264: with minibatch training loss = 3.23 and accuracy of 0.23
Epoch 29, Train loss: 3.23 and Train accuracy of 0.218, Test loss: 3.1 and Test accuracy of 0.254
Iteration 11392: with minibatch training loss = 3.29 and accuracy of 0.21
Iteration 11520: with minibatch training loss = 3.16 and accuracy of 0.2
Iteration 11648: with minibatch training loss = 3.11 and accuracy of 0.23
Epoch 30, Train loss: 3.2 and Train accuracy of 0.223, Test loss: 3.06 and Test accuracy of 0.259
Iteration 11776: with minibatch training loss = 3.39 and accuracy of 0.15
Iteration 11904: with minibatch training loss = 3.22 and accuracy of 0.21
Iteration 12032: with minibatch training loss = 3.08 and accuracy of 0.27
Epoch 31, Train loss: 3.16 and Train accuracy of 0.229, Test loss: 3.03 and Test accuracy of 0.265
Iteration 12160: with minibatch training loss = 3.06 and accuracy of 0.3
Iteration 12288: with minibatch training loss = 2.91 and accuracy of 0.23
Iteration 12416: with minibatch training loss = 3.17 and accuracy of 0.2
Epoch 32, Train loss: 3.13 and Train accuracy of 0.234, Test loss: 3 and Test accuracy of 0.274
Iteration 12544: with minibatch training loss = 3.27 and accuracy of 0.16
Iteration 12672: with minibatch training loss = 3.18 and accuracy of 0.19
Iteration 12800: with minibatch training loss = 3.23 and accuracy of 0.19
Epoch 33, Train loss: 3.1 and Train accuracy of 0.242, Test loss: 2.97 and Test accuracy of 0.277
Iteration 12928: with minibatch training loss = 3.07 and accuracy of 0.23
Iteration 13056: with minibatch training loss = 3.15 and accuracy of 0.3
Iteration 13184: with minibatch training loss = 2.8 and accuracy of 0.31
Epoch 34, Train loss: 3.06 and Train accuracy of 0.248, Test loss: 2.94 and Test accuracy of 0.281
Iteration 13312: with minibatch training loss = 2.9 and accuracy of 0.32
Iteration 13440: with minibatch training loss = 2.75 and accuracy of 0.29
Iteration 13568: with minibatch training loss = 2.97 and accuracy of 0.27
Epoch 35, Train loss: 3.03 and Train accuracy of 0.255, Test loss: 2.93 and Test accuracy of 0.285
Iteration 13696: with minibatch training loss = 2.8 and accuracy of 0.25
Iteration 13824: with minibatch training loss = 3.2 and accuracy of 0.22
Iteration 13952: with minibatch training loss = 2.94 and accuracy of 0.26
Epoch 36, Train loss: 3 and Train accuracy of 0.259, Test loss: 2.88 and Test accuracy of 0.296
Iteration 14080: with minibatch training loss = 2.97 and accuracy of 0.27
Iteration 14208: with minibatch training loss = 2.75 and accuracy of 0.26
Iteration 14336: with minibatch training loss = 3.2 and accuracy of 0.27
Iteration 14464: with minibatch training loss = 2.72 and accuracy of 0.35
Epoch 37, Train loss: 2.98 and Train accuracy of 0.263, Test loss: 2.87 and Test accuracy of 0.297
Iteration 14592: with minibatch training loss = 2.89 and accuracy of 0.26
Iteration 14720: with minibatch training loss = 2.84 and accuracy of 0.3
Iteration 14848: with minibatch training loss = 2.69 and accuracy of 0.31
Epoch 38, Train loss: 2.94 and Train accuracy of 0.27, Test loss: 2.86 and Test accuracy of 0.303
Iteration 14976: with minibatch training loss = 2.79 and accuracy of 0.3
Iteration 15104: with minibatch training loss = 2.91 and accuracy of 0.3
Iteration 15232: with minibatch training loss = 2.91 and accuracy of 0.31
Epoch 39, Train loss: 2.91 and Train accuracy of 0.276, Test loss: 2.84 and Test accuracy of 0.305
Iteration 15360: with minibatch training loss = 2.63 and accuracy of 0.34
Iteration 15488: with minibatch training loss = 2.93 and accuracy of 0.23
Iteration 15616: with minibatch training loss = 2.67 and accuracy of 0.27
Epoch 40, Train loss: 2.88 and Train accuracy of 0.282, Test loss: 2.81 and Test accuracy of 0.31
Iteration 15744: with minibatch training loss = 2.89 and accuracy of 0.34
Iteration 15872: with minibatch training loss = 3.11 and accuracy of 0.24
Iteration 16000: with minibatch training loss = 3.12 and accuracy of 0.26
Epoch 41, Train loss: 2.85 and Train accuracy of 0.287, Test loss: 2.8 and Test accuracy of 0.31
Iteration 16128: with minibatch training loss = 2.81 and accuracy of 0.34
Iteration 16256: with minibatch training loss = 2.71 and accuracy of 0.29
Iteration 16384: with minibatch training loss = 2.72 and accuracy of 0.32
Epoch 42, Train loss: 2.83 and Train accuracy of 0.291, Test loss: 2.77 and Test accuracy of 0.318
Iteration 16512: with minibatch training loss = 3.04 and accuracy of 0.2
Iteration 16640: with minibatch training loss = 3.09 and accuracy of 0.2
Iteration 16768: with minibatch training loss = 2.85 and accuracy of 0.26
Epoch 43, Train loss: 2.8 and Train accuracy of 0.298, Test loss: 2.75 and Test accuracy of 0.32
Iteration 16896: with minibatch training loss = 2.49 and accuracy of 0.36
Iteration 17024: with minibatch training loss = 3.04 and accuracy of 0.27
Iteration 17152: with minibatch training loss = 2.8 and accuracy of 0.25
Epoch 44, Train loss: 2.78 and Train accuracy of 0.302, Test loss: 2.73 and Test accuracy of 0.326
Iteration 17280: with minibatch training loss = 2.82 and accuracy of 0.33
Iteration 17408: with minibatch training loss = 2.65 and accuracy of 0.38
Iteration 17536: with minibatch training loss = 2.86 and accuracy of 0.28
Epoch 45, Train loss: 2.74 and Train accuracy of 0.309, Test loss: 2.72 and Test accuracy of 0.328
Iteration 17664: with minibatch training loss = 2.62 and accuracy of 0.35
Iteration 17792: with minibatch training loss = 3.01 and accuracy of 0.24
Iteration 17920: with minibatch training loss = 2.5 and accuracy of 0.42
Epoch 46, Train loss: 2.71 and Train accuracy of 0.317, Test loss: 2.71 and Test accuracy of 0.33
Iteration 18048: with minibatch training loss = 2.75 and accuracy of 0.28
Iteration 18176: with minibatch training loss = 2.53 and accuracy of 0.34
Iteration 18304: with minibatch training loss = 2.62 and accuracy of 0.31
Epoch 47, Train loss: 2.69 and Train accuracy of 0.317, Test loss: 2.68 and Test accuracy of 0.339
Iteration 18432: with minibatch training loss = 2.69 and accuracy of 0.34
Iteration 18560: with minibatch training loss = 3.04 and accuracy of 0.23
Iteration 18688: with minibatch training loss = 2.65 and accuracy of 0.31
Epoch 48, Train loss: 2.66 and Train accuracy of 0.325, Test loss: 2.67 and Test accuracy of 0.339
Iteration 18816: with minibatch training loss = 2.46 and accuracy of 0.41
Iteration 18944: with minibatch training loss = 2.51 and accuracy of 0.31
Iteration 19072: with minibatch training loss = 2.48 and accuracy of 0.34
Epoch 49, Train loss: 2.63 and Train accuracy of 0.329, Test loss: 2.67 and Test accuracy of 0.338
Iteration 19200: with minibatch training loss = 2.49 and accuracy of 0.39
Iteration 19328: with minibatch training loss = 2.63 and accuracy of 0.29
Iteration 19456: with minibatch training loss = 2.58 and accuracy of 0.32
Epoch 50, Train loss: 2.6 and Train accuracy of 0.336, Test loss: 2.64 and Test accuracy of 0.346
Iteration 19584: with minibatch training loss = 2.85 and accuracy of 0.28
Iteration 19712: with minibatch training loss = 2.49 and accuracy of 0.36
Iteration 19840: with minibatch training loss = 2.39 and accuracy of 0.37
Epoch 51, Train loss: 2.58 and Train accuracy of 0.34, Test loss: 2.62 and Test accuracy of 0.352
Iteration 19968: with minibatch training loss = 2.66 and accuracy of 0.35
Iteration 20096: with minibatch training loss = 2.58 and accuracy of 0.33
Iteration 20224: with minibatch training loss = 2.4 and accuracy of 0.4
Epoch 52, Train loss: 2.55 and Train accuracy of 0.348, Test loss: 2.6 and Test accuracy of 0.353
Iteration 20352: with minibatch training loss = 2.46 and accuracy of 0.38
Iteration 20480: with minibatch training loss = 2.35 and accuracy of 0.37
Iteration 20608: with minibatch training loss = 2.36 and accuracy of 0.38
Epoch 53, Train loss: 2.53 and Train accuracy of 0.35, Test loss: 2.59 and Test accuracy of 0.358
Iteration 20736: with minibatch training loss = 2.85 and accuracy of 0.36
Iteration 20864: with minibatch training loss = 2.46 and accuracy of 0.38
Iteration 20992: with minibatch training loss = 2.57 and accuracy of 0.37
Epoch 54, Train loss: 2.49 and Train accuracy of 0.356, Test loss: 2.59 and Test accuracy of 0.358
Iteration 21120: with minibatch training loss = 2.39 and accuracy of 0.38
Iteration 21248: with minibatch training loss = 2.44 and accuracy of 0.37
Iteration 21376: with minibatch training loss = 2.32 and accuracy of 0.41
Iteration 21504: with minibatch training loss = 2.16 and accuracy of 0.4
Epoch 55, Train loss: 2.48 and Train accuracy of 0.363, Test loss: 2.58 and Test accuracy of 0.359
Iteration 21632: with minibatch training loss = 2.18 and accuracy of 0.45
Iteration 21760: with minibatch training loss = 2.39 and accuracy of 0.34
Iteration 21888: with minibatch training loss = 2.57 and accuracy of 0.33
Epoch 56, Train loss: 2.45 and Train accuracy of 0.369, Test loss: 2.56 and Test accuracy of 0.366
Iteration 22016: with minibatch training loss = 2.54 and accuracy of 0.34
Iteration 22144: with minibatch training loss = 2.22 and accuracy of 0.43
Iteration 22272: with minibatch training loss = 2.44 and accuracy of 0.36
Epoch 57, Train loss: 2.41 and Train accuracy of 0.376, Test loss: 2.55 and Test accuracy of 0.366
Iteration 22400: with minibatch training loss = 2.57 and accuracy of 0.34
Iteration 22528: with minibatch training loss = 2.16 and accuracy of 0.44
Iteration 22656: with minibatch training loss = 2.28 and accuracy of 0.45
Epoch 58, Train loss: 2.39 and Train accuracy of 0.38, Test loss: 2.54 and Test accuracy of 0.368
Iteration 22784: with minibatch training loss = 2.44 and accuracy of 0.36
Iteration 22912: with minibatch training loss = 2.79 and accuracy of 0.31
Iteration 23040: with minibatch training loss = 2.56 and accuracy of 0.31
Epoch 59, Train loss: 2.36 and Train accuracy of 0.383, Test loss: 2.54 and Test accuracy of 0.367
Iteration 23168: with minibatch training loss = 2.53 and accuracy of 0.37
Iteration 23296: with minibatch training loss = 2.35 and accuracy of 0.4
Iteration 23424: with minibatch training loss = 2.51 and accuracy of 0.36
Epoch 60, Train loss: 2.34 and Train accuracy of 0.388, Test loss: 2.52 and Test accuracy of 0.373
Iteration 23552: with minibatch training loss = 2.07 and accuracy of 0.45
Iteration 23680: with minibatch training loss = 2.51 and accuracy of 0.34
Iteration 23808: with minibatch training loss = 2.5 and accuracy of 0.31
Epoch 61, Train loss: 2.31 and Train accuracy of 0.396, Test loss: 2.56 and Test accuracy of 0.366
Iteration 23936: with minibatch training loss = 2.42 and accuracy of 0.34
Iteration 24064: with minibatch training loss = 2.46 and accuracy of 0.29
Iteration 24192: with minibatch training loss = 2.52 and accuracy of 0.35
Epoch 62, Train loss: 2.29 and Train accuracy of 0.399, Test loss: 2.51 and Test accuracy of 0.375
Iteration 24320: with minibatch training loss = 2.02 and accuracy of 0.43
Iteration 24448: with minibatch training loss = 2.36 and accuracy of 0.4
Iteration 24576: with minibatch training loss = 2.04 and accuracy of 0.46
Epoch 63, Train loss: 2.26 and Train accuracy of 0.404, Test loss: 2.51 and Test accuracy of 0.376
Iteration 24704: with minibatch training loss = 2.38 and accuracy of 0.39
Iteration 24832: with minibatch training loss = 2.21 and accuracy of 0.42
Iteration 24960: with minibatch training loss = 2.08 and accuracy of 0.47
Epoch 64, Train loss: 2.23 and Train accuracy of 0.41, Test loss: 2.5 and Test accuracy of 0.379
Iteration 25088: with minibatch training loss = 2.19 and accuracy of 0.45
Iteration 25216: with minibatch training loss = 2.35 and accuracy of 0.37
Iteration 25344: with minibatch training loss = 2.26 and accuracy of 0.38
Epoch 65, Train loss: 2.2 and Train accuracy of 0.416, Test loss: 2.53 and Test accuracy of 0.374
Iteration 25472: with minibatch training loss = 2.21 and accuracy of 0.38
Iteration 25600: with minibatch training loss = 1.99 and accuracy of 0.51
Iteration 25728: with minibatch training loss = 2.08 and accuracy of 0.45
Epoch 66, Train loss: 2.19 and Train accuracy of 0.419, Test loss: 2.53 and Test accuracy of 0.376
Iteration 25856: with minibatch training loss = 2.07 and accuracy of 0.44
Iteration 25984: with minibatch training loss = 2.04 and accuracy of 0.47
Iteration 26112: with minibatch training loss = 2.04 and accuracy of 0.48
Epoch 67, Train loss: 2.15 and Train accuracy of 0.428, Test loss: 2.48 and Test accuracy of 0.386
Iteration 26240: with minibatch training loss = 1.91 and accuracy of 0.5
Iteration 26368: with minibatch training loss = 2.08 and accuracy of 0.48
Iteration 26496: with minibatch training loss = 2.24 and accuracy of 0.39
Epoch 68, Train loss: 2.12 and Train accuracy of 0.432, Test loss: 2.49 and Test accuracy of 0.383
Iteration 26624: with minibatch training loss = 2.22 and accuracy of 0.45
Iteration 26752: with minibatch training loss = 2.01 and accuracy of 0.48
Iteration 26880: with minibatch training loss = 1.81 and accuracy of 0.53
Epoch 69, Train loss: 2.1 and Train accuracy of 0.439, Test loss: 2.48 and Test accuracy of 0.388
Iteration 27008: with minibatch training loss = 1.86 and accuracy of 0.48
Iteration 27136: with minibatch training loss = 2.33 and accuracy of 0.39
Iteration 27264: with minibatch training loss = 2.14 and accuracy of 0.38
Epoch 70, Train loss: 2.07 and Train accuracy of 0.443, Test loss: 2.47 and Test accuracy of 0.384
Iteration 27392: with minibatch training loss = 2.09 and accuracy of 0.42
Iteration 27520: with minibatch training loss = 2.07 and accuracy of 0.44
Iteration 27648: with minibatch training loss = 2.08 and accuracy of 0.5
Epoch 71, Train loss: 2.04 and Train accuracy of 0.449, Test loss: 2.51 and Test accuracy of 0.382
Iteration 27776: with minibatch training loss = 2.13 and accuracy of 0.5
Iteration 27904: with minibatch training loss = 2.06 and accuracy of 0.44
Iteration 28032: with minibatch training loss = 1.95 and accuracy of 0.47
Epoch 72, Train loss: 2.01 and Train accuracy of 0.458, Test loss: 2.49 and Test accuracy of 0.388
Iteration 28160: with minibatch training loss = 2.07 and accuracy of 0.43
Iteration 28288: with minibatch training loss = 2.01 and accuracy of 0.45
Iteration 28416: with minibatch training loss = 2.22 and accuracy of 0.44
Epoch 73, Train loss: 1.98 and Train accuracy of 0.463, Test loss: 2.46 and Test accuracy of 0.394
Iteration 28544: with minibatch training loss = 1.96 and accuracy of 0.46
Iteration 28672: with minibatch training loss = 1.95 and accuracy of 0.45
Iteration 28800: with minibatch training loss = 1.84 and accuracy of 0.52
Iteration 28928: with minibatch training loss = 1.78 and accuracy of 0.52
Epoch 74, Train loss: 1.96 and Train accuracy of 0.469, Test loss: 2.49 and Test accuracy of 0.393
Iteration 29056: with minibatch training loss = 1.96 and accuracy of 0.45
Iteration 29184: with minibatch training loss = 2.02 and accuracy of 0.43
Iteration 29312: with minibatch training loss = 1.98 and accuracy of 0.5
Epoch 75, Train loss: 1.93 and Train accuracy of 0.474, Test loss: 2.47 and Test accuracy of 0.395
Iteration 29440: with minibatch training loss = 1.82 and accuracy of 0.51
Iteration 29568: with minibatch training loss = 1.9 and accuracy of 0.48
Iteration 29696: with minibatch training loss = 1.87 and accuracy of 0.51
Epoch 76, Train loss: 1.9 and Train accuracy of 0.48, Test loss: 2.51 and Test accuracy of 0.394
Iteration 29824: with minibatch training loss = 1.83 and accuracy of 0.48
Iteration 29952: with minibatch training loss = 1.78 and accuracy of 0.52
Iteration 30080: with minibatch training loss = 1.93 and accuracy of 0.44
Epoch 77, Train loss: 1.87 and Train accuracy of 0.485, Test loss: 2.48 and Test accuracy of 0.397
Iteration 30208: with minibatch training loss = 1.76 and accuracy of 0.51
Iteration 30336: with minibatch training loss = 1.71 and accuracy of 0.52
Iteration 30464: with minibatch training loss = 1.84 and accuracy of 0.48
Epoch 78, Train loss: 1.84 and Train accuracy of 0.491, Test loss: 2.51 and Test accuracy of 0.395
Iteration 30592: with minibatch training loss = 1.87 and accuracy of 0.45
Iteration 30720: with minibatch training loss = 2.1 and accuracy of 0.43
Iteration 30848: with minibatch training loss = 1.71 and accuracy of 0.53
Epoch 79, Train loss: 1.81 and Train accuracy of 0.5, Test loss: 2.5 and Test accuracy of 0.395
Iteration 30976: with minibatch training loss = 1.56 and accuracy of 0.59
Iteration 31104: with minibatch training loss = 1.74 and accuracy of 0.53
Iteration 31232: with minibatch training loss = 1.87 and accuracy of 0.48
Epoch 80, Train loss: 1.79 and Train accuracy of 0.506, Test loss: 2.47 and Test accuracy of 0.397
Iteration 31360: with minibatch training loss = 1.81 and accuracy of 0.5
Iteration 31488: with minibatch training loss = 1.66 and accuracy of 0.52
Iteration 31616: with minibatch training loss = 1.63 and accuracy of 0.57
Epoch 81, Train loss: 1.75 and Train accuracy of 0.51, Test loss: 2.53 and Test accuracy of 0.394
Iteration 31744: with minibatch training loss = 1.78 and accuracy of 0.52
Iteration 31872: with minibatch training loss = 1.7 and accuracy of 0.49
Iteration 32000: with minibatch training loss = 1.67 and accuracy of 0.57
Epoch 82, Train loss: 1.73 and Train accuracy of 0.519, Test loss: 2.49 and Test accuracy of 0.399
Iteration 32128: with minibatch training loss = 1.91 and accuracy of 0.49
Iteration 32256: with minibatch training loss = 1.85 and accuracy of 0.48
Iteration 32384: with minibatch training loss = 1.67 and accuracy of 0.5
Epoch 83, Train loss: 1.7 and Train accuracy of 0.527, Test loss: 2.56 and Test accuracy of 0.397
Iteration 32512: with minibatch training loss = 1.71 and accuracy of 0.49
Iteration 32640: with minibatch training loss = 1.69 and accuracy of 0.55
Iteration 32768: with minibatch training loss = 1.44 and accuracy of 0.6
Epoch 84, Train loss: 1.67 and Train accuracy of 0.529, Test loss: 2.54 and Test accuracy of 0.398
Iteration 32896: with minibatch training loss = 1.63 and accuracy of 0.56
Iteration 33024: with minibatch training loss = 1.84 and accuracy of 0.41
Iteration 33152: with minibatch training loss = 1.68 and accuracy of 0.52
Epoch 85, Train loss: 1.65 and Train accuracy of 0.534, Test loss: 2.51 and Test accuracy of 0.4
Iteration 33280: with minibatch training loss = 1.72 and accuracy of 0.49
Iteration 33408: with minibatch training loss = 1.69 and accuracy of 0.53
Iteration 33536: with minibatch training loss = 1.45 and accuracy of 0.61
Epoch 86, Train loss: 1.61 and Train accuracy of 0.544, Test loss: 2.58 and Test accuracy of 0.397
Iteration 33664: with minibatch training loss = 1.56 and accuracy of 0.54
Iteration 33792: with minibatch training loss = 1.48 and accuracy of 0.57
Iteration 33920: with minibatch training loss = 1.62 and accuracy of 0.52
Epoch 87, Train loss: 1.59 and Train accuracy of 0.548, Test loss: 2.5 and Test accuracy of 0.405
Iteration 34048: with minibatch training loss = 1.67 and accuracy of 0.55
Iteration 34176: with minibatch training loss = 1.45 and accuracy of 0.54
Iteration 34304: with minibatch training loss = 1.39 and accuracy of 0.55
Epoch 88, Train loss: 1.55 and Train accuracy of 0.556, Test loss: 2.55 and Test accuracy of 0.403
Iteration 34432: with minibatch training loss = 1.57 and accuracy of 0.55
Iteration 34560: with minibatch training loss = 1.39 and accuracy of 0.6
Iteration 34688: with minibatch training loss = 1.53 and accuracy of 0.54
Epoch 89, Train loss: 1.53 and Train accuracy of 0.563, Test loss: 2.62 and Test accuracy of 0.398
Iteration 34816: with minibatch training loss = 1.91 and accuracy of 0.47
Iteration 34944: with minibatch training loss = 1.74 and accuracy of 0.49
Iteration 35072: with minibatch training loss = 1.39 and accuracy of 0.55
Epoch 90, Train loss: 1.5 and Train accuracy of 0.571, Test loss: 2.55 and Test accuracy of 0.401
Iteration 35200: with minibatch training loss = 1.67 and accuracy of 0.48
Iteration 35328: with minibatch training loss = 1.43 and accuracy of 0.56
Iteration 35456: with minibatch training loss = 1.28 and accuracy of 0.59
Epoch 91, Train loss: 1.48 and Train accuracy of 0.574, Test loss: 2.55 and Test accuracy of 0.397
Iteration 35584: with minibatch training loss = 1.73 and accuracy of 0.47
Iteration 35712: with minibatch training loss = 1.57 and accuracy of 0.55
Iteration 35840: with minibatch training loss = 1.28 and accuracy of 0.67
Iteration 35968: with minibatch training loss = 1.36 and accuracy of 0.58
Epoch 92, Train loss: 1.45 and Train accuracy of 0.578, Test loss: 2.56 and Test accuracy of 0.403
Iteration 36096: with minibatch training loss = 1.45 and accuracy of 0.6
Iteration 36224: with minibatch training loss = 1.37 and accuracy of 0.6
Iteration 36352: with minibatch training loss = 1.5 and accuracy of 0.57
Epoch 93, Train loss: 1.42 and Train accuracy of 0.588, Test loss: 2.61 and Test accuracy of 0.399
Iteration 36480: with minibatch training loss = 1.56 and accuracy of 0.62
Iteration 36608: with minibatch training loss = 1.37 and accuracy of 0.56
Iteration 36736: with minibatch training loss = 1.61 and accuracy of 0.58
Epoch 94, Train loss: 1.39 and Train accuracy of 0.595, Test loss: 2.58 and Test accuracy of 0.404
Iteration 36864: with minibatch training loss = 1.47 and accuracy of 0.57
Iteration 36992: with minibatch training loss = 1.16 and accuracy of 0.67
Iteration 37120: with minibatch training loss = 1.19 and accuracy of 0.67
Epoch 95, Train loss: 1.36 and Train accuracy of 0.604, Test loss: 2.62 and Test accuracy of 0.403
Iteration 37248: with minibatch training loss = 1.56 and accuracy of 0.53
Iteration 37376: with minibatch training loss = 1.19 and accuracy of 0.62
Iteration 37504: with minibatch training loss = 1.38 and accuracy of 0.6
Epoch 96, Train loss: 1.33 and Train accuracy of 0.609, Test loss: 2.62 and Test accuracy of 0.402
Iteration 37632: with minibatch training loss = 1.44 and accuracy of 0.63
Iteration 37760: with minibatch training loss = 1.2 and accuracy of 0.59
Iteration 37888: with minibatch training loss = 1.27 and accuracy of 0.63
Epoch 97, Train loss: 1.32 and Train accuracy of 0.615, Test loss: 2.71 and Test accuracy of 0.397
Iteration 38016: with minibatch training loss = 1.13 and accuracy of 0.66
Iteration 38144: with minibatch training loss = 1.12 and accuracy of 0.66
Iteration 38272: with minibatch training loss = 1.37 and accuracy of 0.59
Epoch 98, Train loss: 1.29 and Train accuracy of 0.622, Test loss: 2.65 and Test accuracy of 0.403
Iteration 38400: with minibatch training loss = 1.28 and accuracy of 0.63
Iteration 38528: with minibatch training loss = 1.12 and accuracy of 0.7
Iteration 38656: with minibatch training loss = 1.2 and accuracy of 0.63
Epoch 99, Train loss: 1.25 and Train accuracy of 0.633, Test loss: 2.66 and Test accuracy of 0.398
Iteration 38784: with minibatch training loss = 1.18 and accuracy of 0.64
Iteration 38912: with minibatch training loss = 0.958 and accuracy of 0.7
Iteration 39040: with minibatch training loss = 1.1 and accuracy of 0.67
Epoch 100, Train loss: 1.24 and Train accuracy of 0.634, Test loss: 2.69 and Test accuracy of 0.401
24:37:39
