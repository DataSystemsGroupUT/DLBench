Training
Iteration 0: with minibatch training loss = 2.75 and accuracy of 0.16
Iteration 128: with minibatch training loss = 1.02 and accuracy of 0.75
Iteration 256: with minibatch training loss = 0.872 and accuracy of 0.83
Iteration 384: with minibatch training loss = 0.588 and accuracy of 0.92
Epoch 1, Overall loss = 0.934 and accuracy of 0.779
Iteration 512: with minibatch training loss = 0.542 and accuracy of 0.9
Iteration 640: with minibatch training loss = 0.429 and accuracy of 0.92
Iteration 768: with minibatch training loss = 0.348 and accuracy of 0.96
Iteration 896: with minibatch training loss = 0.327 and accuracy of 0.95
Epoch 2, Overall loss = 0.424 and accuracy of 0.927
Iteration 1024: with minibatch training loss = 0.257 and accuracy of 0.99
Iteration 1152: with minibatch training loss = 0.332 and accuracy of 0.93
Iteration 1280: with minibatch training loss = 0.326 and accuracy of 0.92
Epoch 3, Overall loss = 0.288 and accuracy of 0.95
Iteration 1408: with minibatch training loss = 0.224 and accuracy of 0.98
Iteration 1536: with minibatch training loss = 0.273 and accuracy of 0.93
Iteration 1664: with minibatch training loss = 0.201 and accuracy of 0.95
Iteration 1792: with minibatch training loss = 0.21 and accuracy of 0.97
Epoch 4, Overall loss = 0.223 and accuracy of 0.961
Iteration 1920: with minibatch training loss = 0.196 and accuracy of 0.96
Iteration 2048: with minibatch training loss = 0.208 and accuracy of 0.94
Iteration 2176: with minibatch training loss = 0.226 and accuracy of 0.95
Iteration 2304: with minibatch training loss = 0.149 and accuracy of 0.98
Epoch 5, Overall loss = 0.186 and accuracy of 0.966
Iteration 2432: with minibatch training loss = 0.161 and accuracy of 0.96
Iteration 2560: with minibatch training loss = 0.181 and accuracy of 0.97
Iteration 2688: with minibatch training loss = 0.175 and accuracy of 0.96
Epoch 6, Overall loss = 0.164 and accuracy of 0.969
Iteration 2816: with minibatch training loss = 0.14 and accuracy of 0.98
Iteration 2944: with minibatch training loss = 0.163 and accuracy of 0.95
Iteration 3072: with minibatch training loss = 0.119 and accuracy of 0.98
Iteration 3200: with minibatch training loss = 0.112 and accuracy of 0.99
Epoch 7, Overall loss = 0.144 and accuracy of 0.973
Iteration 3328: with minibatch training loss = 0.128 and accuracy of 0.98
Iteration 3456: with minibatch training loss = 0.109 and accuracy of 0.98
Iteration 3584: with minibatch training loss = 0.162 and accuracy of 0.98
Iteration 3712: with minibatch training loss = 0.144 and accuracy of 0.96
Epoch 8, Overall loss = 0.131 and accuracy of 0.975
Iteration 3840: with minibatch training loss = 0.0627 and accuracy of 1
Iteration 3968: with minibatch training loss = 0.0934 and accuracy of 0.99
Iteration 4096: with minibatch training loss = 0.0917 and accuracy of 0.99
Epoch 9, Overall loss = 0.122 and accuracy of 0.976
Iteration 4224: with minibatch training loss = 0.103 and accuracy of 0.98
Iteration 4352: with minibatch training loss = 0.109 and accuracy of 0.98
Iteration 4480: with minibatch training loss = 0.0785 and accuracy of 0.98
Iteration 4608: with minibatch training loss = 0.149 and accuracy of 0.97
Epoch 10, Overall loss = 0.112 and accuracy of 0.978
Iteration 4736: with minibatch training loss = 0.0828 and accuracy of 0.98
Iteration 4864: with minibatch training loss = 0.118 and accuracy of 0.98
Iteration 4992: with minibatch training loss = 0.0921 and accuracy of 0.96
Epoch 11, Overall loss = 0.104 and accuracy of 0.979
Iteration 5120: with minibatch training loss = 0.0914 and accuracy of 0.98
Iteration 5248: with minibatch training loss = 0.105 and accuracy of 0.98
Iteration 5376: with minibatch training loss = 0.114 and accuracy of 0.98
Iteration 5504: with minibatch training loss = 0.0642 and accuracy of 0.98
Epoch 12, Overall loss = 0.0983 and accuracy of 0.98
Iteration 5632: with minibatch training loss = 0.0761 and accuracy of 0.98
Iteration 5760: with minibatch training loss = 0.0875 and accuracy of 0.98
Iteration 5888: with minibatch training loss = 0.111 and accuracy of 0.98
Iteration 6016: with minibatch training loss = 0.0676 and accuracy of 0.99
Epoch 13, Overall loss = 0.0931 and accuracy of 0.981
Iteration 6144: with minibatch training loss = 0.107 and accuracy of 0.97
Iteration 6272: with minibatch training loss = 0.105 and accuracy of 0.96
Iteration 6400: with minibatch training loss = 0.0981 and accuracy of 0.98
Epoch 14, Overall loss = 0.0888 and accuracy of 0.982
Iteration 6528: with minibatch training loss = 0.0762 and accuracy of 0.98
Iteration 6656: with minibatch training loss = 0.0499 and accuracy of 1
Iteration 6784: with minibatch training loss = 0.0823 and accuracy of 0.99
Iteration 6912: with minibatch training loss = 0.106 and accuracy of 0.98
Epoch 15, Overall loss = 0.0845 and accuracy of 0.982
Validation
Epoch 1, Overall loss = 0.0836 and accuracy of 0.98
Training
Epoch 1, Overall loss = 0.0311 and accuracy of 0.994
Validation
Epoch 1, Overall loss = 0.0836 and accuracy of 0.98
Test
Epoch 1, Overall loss = 0.0386 and accuracy of 0.99
0:43:00.898827