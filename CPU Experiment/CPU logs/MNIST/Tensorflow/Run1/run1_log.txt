Training
Iteration 0: with minibatch training loss = 2.7 and accuracy of 0.12
Iteration 128: with minibatch training loss = 0.861 and accuracy of 0.85
Iteration 256: with minibatch training loss = 0.749 and accuracy of 0.84
Iteration 384: with minibatch training loss = 0.497 and accuracy of 0.93
Epoch 1, Overall loss = 0.826 and accuracy of 0.826
Iteration 512: with minibatch training loss = 0.456 and accuracy of 0.9
Iteration 640: with minibatch training loss = 0.385 and accuracy of 0.91
Iteration 768: with minibatch training loss = 0.442 and accuracy of 0.89
Iteration 896: with minibatch training loss = 0.309 and accuracy of 0.95
Epoch 2, Overall loss = 0.381 and accuracy of 0.938
Iteration 1024: with minibatch training loss = 0.316 and accuracy of 0.93
Iteration 1152: with minibatch training loss = 0.232 and accuracy of 0.96
Iteration 1280: with minibatch training loss = 0.274 and accuracy of 0.95
Epoch 3, Overall loss = 0.264 and accuracy of 0.956
Iteration 1408: with minibatch training loss = 0.246 and accuracy of 0.95
Iteration 1536: with minibatch training loss = 0.181 and accuracy of 0.98
Iteration 1664: with minibatch training loss = 0.181 and accuracy of 0.98
Iteration 1792: with minibatch training loss = 0.221 and accuracy of 0.96
Epoch 4, Overall loss = 0.21 and accuracy of 0.962
Iteration 1920: with minibatch training loss = 0.188 and accuracy of 0.96
Iteration 2048: with minibatch training loss = 0.192 and accuracy of 0.98
Iteration 2176: with minibatch training loss = 0.134 and accuracy of 0.97
Iteration 2304: with minibatch training loss = 0.19 and accuracy of 0.97
Epoch 5, Overall loss = 0.178 and accuracy of 0.967
Iteration 2432: with minibatch training loss = 0.13 and accuracy of 0.98
Iteration 2560: with minibatch training loss = 0.109 and accuracy of 0.98
Iteration 2688: with minibatch training loss = 0.189 and accuracy of 0.99
Epoch 6, Overall loss = 0.156 and accuracy of 0.971
Iteration 2816: with minibatch training loss = 0.166 and accuracy of 0.96
Iteration 2944: with minibatch training loss = 0.173 and accuracy of 0.97
Iteration 3072: with minibatch training loss = 0.116 and accuracy of 0.99
Iteration 3200: with minibatch training loss = 0.191 and accuracy of 0.96
Epoch 7, Overall loss = 0.14 and accuracy of 0.974
Iteration 3328: with minibatch training loss = 0.105 and accuracy of 0.98
Iteration 3456: with minibatch training loss = 0.131 and accuracy of 0.98
Iteration 3584: with minibatch training loss = 0.1 and accuracy of 0.98
Iteration 3712: with minibatch training loss = 0.105 and accuracy of 0.98
Epoch 8, Overall loss = 0.128 and accuracy of 0.974
Iteration 3840: with minibatch training loss = 0.179 and accuracy of 0.96
Iteration 3968: with minibatch training loss = 0.0801 and accuracy of 1
Iteration 4096: with minibatch training loss = 0.152 and accuracy of 0.98
Epoch 9, Overall loss = 0.116 and accuracy of 0.978
Iteration 4224: with minibatch training loss = 0.186 and accuracy of 0.95
Iteration 4352: with minibatch training loss = 0.138 and accuracy of 0.97
Iteration 4480: with minibatch training loss = 0.0953 and accuracy of 0.99
Iteration 4608: with minibatch training loss = 0.0976 and accuracy of 0.98
Epoch 10, Overall loss = 0.11 and accuracy of 0.977
Iteration 4736: with minibatch training loss = 0.0791 and accuracy of 0.99
Iteration 4864: with minibatch training loss = 0.124 and accuracy of 0.96
Iteration 4992: with minibatch training loss = 0.111 and accuracy of 0.97
Epoch 11, Overall loss = 0.103 and accuracy of 0.979
Iteration 5120: with minibatch training loss = 0.0669 and accuracy of 0.99
Iteration 5248: with minibatch training loss = 0.0897 and accuracy of 0.97
Iteration 5376: with minibatch training loss = 0.0895 and accuracy of 0.98
Iteration 5504: with minibatch training loss = 0.113 and accuracy of 0.98
Epoch 12, Overall loss = 0.0975 and accuracy of 0.98
Iteration 5632: with minibatch training loss = 0.102 and accuracy of 0.98
Iteration 5760: with minibatch training loss = 0.0754 and accuracy of 0.99
Iteration 5888: with minibatch training loss = 0.0828 and accuracy of 0.98
Iteration 6016: with minibatch training loss = 0.119 and accuracy of 0.98
Epoch 13, Overall loss = 0.091 and accuracy of 0.981
Iteration 6144: with minibatch training loss = 0.0648 and accuracy of 0.99
Iteration 6272: with minibatch training loss = 0.0617 and accuracy of 0.98
Iteration 6400: with minibatch training loss = 0.0537 and accuracy of 0.98
Epoch 14, Overall loss = 0.0872 and accuracy of 0.982
Iteration 6528: with minibatch training loss = 0.0928 and accuracy of 0.98
Iteration 6656: with minibatch training loss = 0.117 and accuracy of 0.98
Iteration 6784: with minibatch training loss = 0.108 and accuracy of 0.97
Iteration 6912: with minibatch training loss = 0.106 and accuracy of 0.98
Epoch 15, Overall loss = 0.0839 and accuracy of 0.983
Validation
Epoch 1, Overall loss = 0.0803 and accuracy of 0.982
Training
Epoch 1, Overall loss = 0.0342 and accuracy of 0.993
Validation
Epoch 1, Overall loss = 0.0803 and accuracy of 0.982
Test
Epoch 1, Overall loss = 0.0424 and accuracy of 0.988
0:41:11.165148