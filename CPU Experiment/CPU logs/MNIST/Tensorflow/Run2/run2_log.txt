Training
Iteration 0: with minibatch training loss = 2.75 and accuracy of 0.086
Iteration 128: with minibatch training loss = 0.961 and accuracy of 0.79
Iteration 256: with minibatch training loss = 0.679 and accuracy of 0.89
Iteration 384: with minibatch training loss = 0.475 and accuracy of 0.95
Epoch 1, Overall loss = 0.811 and accuracy of 0.829
Iteration 512: with minibatch training loss = 0.482 and accuracy of 0.92
Iteration 640: with minibatch training loss = 0.444 and accuracy of 0.9
Iteration 768: with minibatch training loss = 0.295 and accuracy of 0.96
Iteration 896: with minibatch training loss = 0.348 and accuracy of 0.93
Epoch 2, Overall loss = 0.377 and accuracy of 0.939
Iteration 1024: with minibatch training loss = 0.345 and accuracy of 0.92
Iteration 1152: with minibatch training loss = 0.27 and accuracy of 0.95
Iteration 1280: with minibatch training loss = 0.282 and accuracy of 0.94
Epoch 3, Overall loss = 0.267 and accuracy of 0.954
Iteration 1408: with minibatch training loss = 0.229 and accuracy of 0.95
Iteration 1536: with minibatch training loss = 0.247 and accuracy of 0.95
Iteration 1664: with minibatch training loss = 0.159 and accuracy of 0.98
Iteration 1792: with minibatch training loss = 0.179 and accuracy of 0.97
Epoch 4, Overall loss = 0.212 and accuracy of 0.962
Iteration 1920: with minibatch training loss = 0.216 and accuracy of 0.95
Iteration 2048: with minibatch training loss = 0.187 and accuracy of 0.95
Iteration 2176: with minibatch training loss = 0.0899 and accuracy of 1
Iteration 2304: with minibatch training loss = 0.17 and accuracy of 0.96
Epoch 5, Overall loss = 0.18 and accuracy of 0.967
Iteration 2432: with minibatch training loss = 0.14 and accuracy of 0.97
Iteration 2560: with minibatch training loss = 0.167 and accuracy of 0.94
Iteration 2688: with minibatch training loss = 0.147 and accuracy of 0.97
Epoch 6, Overall loss = 0.157 and accuracy of 0.97
Iteration 2816: with minibatch training loss = 0.164 and accuracy of 0.97
Iteration 2944: with minibatch training loss = 0.151 and accuracy of 0.98
Iteration 3072: with minibatch training loss = 0.134 and accuracy of 0.96
Iteration 3200: with minibatch training loss = 0.145 and accuracy of 0.97
Epoch 7, Overall loss = 0.14 and accuracy of 0.973
Iteration 3328: with minibatch training loss = 0.185 and accuracy of 0.95
Iteration 3456: with minibatch training loss = 0.127 and accuracy of 0.99
Iteration 3584: with minibatch training loss = 0.171 and accuracy of 0.97
Iteration 3712: with minibatch training loss = 0.183 and accuracy of 0.93
Epoch 8, Overall loss = 0.127 and accuracy of 0.976
Iteration 3840: with minibatch training loss = 0.0753 and accuracy of 0.99
Iteration 3968: with minibatch training loss = 0.132 and accuracy of 0.97
Iteration 4096: with minibatch training loss = 0.117 and accuracy of 0.97
Epoch 9, Overall loss = 0.117 and accuracy of 0.977
Iteration 4224: with minibatch training loss = 0.0705 and accuracy of 0.99
Iteration 4352: with minibatch training loss = 0.0756 and accuracy of 0.99
Iteration 4480: with minibatch training loss = 0.172 and accuracy of 0.95
Iteration 4608: with minibatch training loss = 0.121 and accuracy of 0.97
Epoch 10, Overall loss = 0.11 and accuracy of 0.978
Iteration 4736: with minibatch training loss = 0.0816 and accuracy of 0.99
Iteration 4864: with minibatch training loss = 0.0845 and accuracy of 0.98
Iteration 4992: with minibatch training loss = 0.0823 and accuracy of 1
Epoch 11, Overall loss = 0.101 and accuracy of 0.98
Iteration 5120: with minibatch training loss = 0.159 and accuracy of 0.95
Iteration 5248: with minibatch training loss = 0.103 and accuracy of 0.98
Iteration 5376: with minibatch training loss = 0.112 and accuracy of 0.97
Iteration 5504: with minibatch training loss = 0.124 and accuracy of 0.95
Epoch 12, Overall loss = 0.0978 and accuracy of 0.979
Iteration 5632: with minibatch training loss = 0.0879 and accuracy of 0.99
Iteration 5760: with minibatch training loss = 0.082 and accuracy of 0.99
Iteration 5888: with minibatch training loss = 0.15 and accuracy of 0.95
Iteration 6016: with minibatch training loss = 0.0712 and accuracy of 0.99
Epoch 13, Overall loss = 0.0922 and accuracy of 0.981
Iteration 6144: with minibatch training loss = 0.0919 and accuracy of 0.98
Iteration 6272: with minibatch training loss = 0.0686 and accuracy of 0.98
Iteration 6400: with minibatch training loss = 0.0559 and accuracy of 1
Epoch 14, Overall loss = 0.0868 and accuracy of 0.983
Iteration 6528: with minibatch training loss = 0.0681 and accuracy of 0.98
Iteration 6656: with minibatch training loss = 0.0625 and accuracy of 0.98
Iteration 6784: with minibatch training loss = 0.0724 and accuracy of 0.99
Iteration 6912: with minibatch training loss = 0.0441 and accuracy of 1
Epoch 15, Overall loss = 0.0827 and accuracy of 0.983
Validation
Epoch 1, Overall loss = 0.0777 and accuracy of 0.982
Training
Epoch 1, Overall loss = 0.0345 and accuracy of 0.993
Validation
Epoch 1, Overall loss = 0.0777 and accuracy of 0.982
Test
Epoch 1, Overall loss = 0.0492 and accuracy of 0.986
0:41:13.072831