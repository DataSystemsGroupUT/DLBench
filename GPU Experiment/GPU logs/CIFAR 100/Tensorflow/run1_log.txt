Loading data...
(50000, 32, 32, 3)
(50000,)
(10000, 32, 32, 3)
(10000,)
####################
(?, 32, 32, 128)
(?, 30, 30, 128)
(?, 15, 15, 128)
(?, 15, 15, 256)
(?, 13, 13, 256)
(?, 6, 6, 256)
(?, 6, 6, 512)
(?, 4, 4, 512)
(?, 2, 2, 512)
Training
Iteration 0: with minibatch training loss = 4.61 and accuracy of 0.016
Iteration 128: with minibatch training loss = 4.6 and accuracy of 0.0078
Iteration 256: with minibatch training loss = 4.59 and accuracy of 0.023
Iteration 384: with minibatch training loss = 4.6 and accuracy of 0.016
Epoch 1, Train loss: 4.61 and Train accuracy of 0.0104, Test loss: 4.61 and Test accuracy of 0.01
Iteration 512: with minibatch training loss = 4.6 and accuracy of 0.0078
Iteration 640: with minibatch training loss = 4.58 and accuracy of 0.031
Iteration 768: with minibatch training loss = 4.61 and accuracy of 0
Epoch 2, Train loss: 4.61 and Train accuracy of 0.0108, Test loss: 4.6 and Test accuracy of 0.021
Iteration 896: with minibatch training loss = 4.6 and accuracy of 0.016
Iteration 1024: with minibatch training loss = 4.57 and accuracy of 0.016
Iteration 1152: with minibatch training loss = 4.59 and accuracy of 0.016
Epoch 3, Train loss: 4.59 and Train accuracy of 0.0172, Test loss: 4.54 and Test accuracy of 0.0247
Iteration 1280: with minibatch training loss = 4.57 and accuracy of 0.0078
Iteration 1408: with minibatch training loss = 4.54 and accuracy of 0.016
Iteration 1536: with minibatch training loss = 4.53 and accuracy of 0.016
Epoch 4, Train loss: 4.53 and Train accuracy of 0.0212, Test loss: 4.47 and Test accuracy of 0.0348
Iteration 1664: with minibatch training loss = 4.59 and accuracy of 0
Iteration 1792: with minibatch training loss = 4.48 and accuracy of 0.047
Iteration 1920: with minibatch training loss = 4.34 and accuracy of 0.07
Epoch 5, Train loss: 4.45 and Train accuracy of 0.0313, Test loss: 4.32 and Test accuracy of 0.0426
Iteration 2048: with minibatch training loss = 4.22 and accuracy of 0.023
Iteration 2176: with minibatch training loss = 4.27 and accuracy of 0.039
Iteration 2304: with minibatch training loss = 4.35 and accuracy of 0.031
Epoch 6, Train loss: 4.33 and Train accuracy of 0.0409, Test loss: 4.2 and Test accuracy of 0.0665
Iteration 2432: with minibatch training loss = 4.35 and accuracy of 0.047
Iteration 2560: with minibatch training loss = 4.12 and accuracy of 0.047
Iteration 2688: with minibatch training loss = 4.2 and accuracy of 0.055
Epoch 7, Train loss: 4.23 and Train accuracy of 0.053, Test loss: 4.09 and Test accuracy of 0.0816
Iteration 2816: with minibatch training loss = 4.2 and accuracy of 0.078
Iteration 2944: with minibatch training loss = 4.05 and accuracy of 0.086
Iteration 3072: with minibatch training loss = 4.12 and accuracy of 0.086
Epoch 8, Train loss: 4.14 and Train accuracy of 0.0636, Test loss: 4.01 and Test accuracy of 0.0958
Iteration 3200: with minibatch training loss = 4.16 and accuracy of 0.062
Iteration 3328: with minibatch training loss = 3.99 and accuracy of 0.086
Iteration 3456: with minibatch training loss = 4.14 and accuracy of 0.055
Epoch 9, Train loss: 4.07 and Train accuracy of 0.0756, Test loss: 3.93 and Test accuracy of 0.107
Iteration 3584: with minibatch training loss = 4.19 and accuracy of 0.039
Iteration 3712: with minibatch training loss = 3.91 and accuracy of 0.086
Iteration 3840: with minibatch training loss = 3.84 and accuracy of 0.094
Epoch 10, Train loss: 4 and Train accuracy of 0.0822, Test loss: 3.85 and Test accuracy of 0.116
Iteration 3968: with minibatch training loss = 3.95 and accuracy of 0.086
Iteration 4096: with minibatch training loss = 3.88 and accuracy of 0.15
Iteration 4224: with minibatch training loss = 3.73 and accuracy of 0.12
Epoch 11, Train loss: 3.94 and Train accuracy of 0.0931, Test loss: 3.78 and Test accuracy of 0.128
Iteration 4352: with minibatch training loss = 4.19 and accuracy of 0.039
Iteration 4480: with minibatch training loss = 3.67 and accuracy of 0.15
Iteration 4608: with minibatch training loss = 3.85 and accuracy of 0.078
Epoch 12, Train loss: 3.88 and Train accuracy of 0.104, Test loss: 3.72 and Test accuracy of 0.139
Iteration 4736: with minibatch training loss = 3.97 and accuracy of 0.094
Iteration 4864: with minibatch training loss = 3.98 and accuracy of 0.094
Iteration 4992: with minibatch training loss = 3.81 and accuracy of 0.094
Epoch 13, Train loss: 3.82 and Train accuracy of 0.112, Test loss: 3.67 and Test accuracy of 0.149
Iteration 5120: with minibatch training loss = 3.84 and accuracy of 0.13
Iteration 5248: with minibatch training loss = 3.77 and accuracy of 0.13
Iteration 5376: with minibatch training loss = 3.81 and accuracy of 0.12
Epoch 14, Train loss: 3.78 and Train accuracy of 0.12, Test loss: 3.63 and Test accuracy of 0.153
Iteration 5504: with minibatch training loss = 3.69 and accuracy of 0.12
Iteration 5632: with minibatch training loss = 3.81 and accuracy of 0.12
Iteration 5760: with minibatch training loss = 3.74 and accuracy of 0.11
Epoch 15, Train loss: 3.74 and Train accuracy of 0.125, Test loss: 3.6 and Test accuracy of 0.162
Iteration 5888: with minibatch training loss = 3.62 and accuracy of 0.13
Iteration 6016: with minibatch training loss = 3.95 and accuracy of 0.1
Iteration 6144: with minibatch training loss = 3.74 and accuracy of 0.12
Epoch 16, Train loss: 3.7 and Train accuracy of 0.13, Test loss: 3.56 and Test accuracy of 0.167
Iteration 6272: with minibatch training loss = 3.57 and accuracy of 0.15
Iteration 6400: with minibatch training loss = 3.88 and accuracy of 0.12
Iteration 6528: with minibatch training loss = 3.55 and accuracy of 0.16
Epoch 17, Train loss: 3.67 and Train accuracy of 0.136, Test loss: 3.53 and Test accuracy of 0.173
Iteration 6656: with minibatch training loss = 3.47 and accuracy of 0.14
Iteration 6784: with minibatch training loss = 3.68 and accuracy of 0.12
Iteration 6912: with minibatch training loss = 3.52 and accuracy of 0.14
Epoch 18, Train loss: 3.63 and Train accuracy of 0.141, Test loss: 3.49 and Test accuracy of 0.179
Iteration 7040: with minibatch training loss = 3.57 and accuracy of 0.15
Iteration 7168: with minibatch training loss = 3.48 and accuracy of 0.18
Iteration 7296: with minibatch training loss = 3.48 and accuracy of 0.18
Iteration 7424: with minibatch training loss = 3.44 and accuracy of 0.16
Epoch 19, Train loss: 3.59 and Train accuracy of 0.154, Test loss: 3.45 and Test accuracy of 0.184
Iteration 7552: with minibatch training loss = 3.89 and accuracy of 0.15
Iteration 7680: with minibatch training loss = 3.62 and accuracy of 0.16
Iteration 7808: with minibatch training loss = 3.81 and accuracy of 0.14
Epoch 20, Train loss: 3.56 and Train accuracy of 0.155, Test loss: 3.42 and Test accuracy of 0.194
Iteration 7936: with minibatch training loss = 3.54 and accuracy of 0.16
Iteration 8064: with minibatch training loss = 3.4 and accuracy of 0.18
Iteration 8192: with minibatch training loss = 3.44 and accuracy of 0.19
Epoch 21, Train loss: 3.52 and Train accuracy of 0.163, Test loss: 3.4 and Test accuracy of 0.196
Iteration 8320: with minibatch training loss = 3.46 and accuracy of 0.17
Iteration 8448: with minibatch training loss = 3.45 and accuracy of 0.11
Iteration 8576: with minibatch training loss = 3.57 and accuracy of 0.17
Epoch 22, Train loss: 3.49 and Train accuracy of 0.168, Test loss: 3.36 and Test accuracy of 0.203
Iteration 8704: with minibatch training loss = 3.34 and accuracy of 0.22
Iteration 8832: with minibatch training loss = 3.47 and accuracy of 0.17
Iteration 8960: with minibatch training loss = 3.44 and accuracy of 0.2
Epoch 23, Train loss: 3.45 and Train accuracy of 0.175, Test loss: 3.33 and Test accuracy of 0.207
Iteration 9088: with minibatch training loss = 3.48 and accuracy of 0.16
Iteration 9216: with minibatch training loss = 3.32 and accuracy of 0.16
Iteration 9344: with minibatch training loss = 3.53 and accuracy of 0.18
Epoch 24, Train loss: 3.42 and Train accuracy of 0.18, Test loss: 3.28 and Test accuracy of 0.215
Iteration 9472: with minibatch training loss = 3.49 and accuracy of 0.16
Iteration 9600: with minibatch training loss = 3.38 and accuracy of 0.18
Iteration 9728: with minibatch training loss = 3.4 and accuracy of 0.2
Epoch 25, Train loss: 3.38 and Train accuracy of 0.188, Test loss: 3.25 and Test accuracy of 0.226
Iteration 9856: with minibatch training loss = 3.26 and accuracy of 0.23
Iteration 9984: with minibatch training loss = 3.25 and accuracy of 0.23
Iteration 10112: with minibatch training loss = 3.23 and accuracy of 0.2
Epoch 26, Train loss: 3.35 and Train accuracy of 0.194, Test loss: 3.22 and Test accuracy of 0.23
Iteration 10240: with minibatch training loss = 3.46 and accuracy of 0.23
Iteration 10368: with minibatch training loss = 2.96 and accuracy of 0.29
Iteration 10496: with minibatch training loss = 3.34 and accuracy of 0.15
Epoch 27, Train loss: 3.31 and Train accuracy of 0.201, Test loss: 3.19 and Test accuracy of 0.235
Iteration 10624: with minibatch training loss = 3.44 and accuracy of 0.19
Iteration 10752: with minibatch training loss = 3.08 and accuracy of 0.29
Iteration 10880: with minibatch training loss = 3.01 and accuracy of 0.29
Epoch 28, Train loss: 3.27 and Train accuracy of 0.209, Test loss: 3.17 and Test accuracy of 0.239
Iteration 11008: with minibatch training loss = 3.25 and accuracy of 0.2
Iteration 11136: with minibatch training loss = 3.37 and accuracy of 0.19
Iteration 11264: with minibatch training loss = 2.96 and accuracy of 0.28
Epoch 29, Train loss: 3.24 and Train accuracy of 0.213, Test loss: 3.12 and Test accuracy of 0.247
Iteration 11392: with minibatch training loss = 3.38 and accuracy of 0.19
Iteration 11520: with minibatch training loss = 3.06 and accuracy of 0.2
Iteration 11648: with minibatch training loss = 3.21 and accuracy of 0.23
Epoch 30, Train loss: 3.21 and Train accuracy of 0.221, Test loss: 3.1 and Test accuracy of 0.253
Iteration 11776: with minibatch training loss = 3.35 and accuracy of 0.17
Iteration 11904: with minibatch training loss = 3.29 and accuracy of 0.16
Iteration 12032: with minibatch training loss = 3.22 and accuracy of 0.19
Epoch 31, Train loss: 3.18 and Train accuracy of 0.225, Test loss: 3.07 and Test accuracy of 0.262
Iteration 12160: with minibatch training loss = 3.14 and accuracy of 0.2
Iteration 12288: with minibatch training loss = 3.16 and accuracy of 0.27
Iteration 12416: with minibatch training loss = 3.26 and accuracy of 0.23
Epoch 32, Train loss: 3.15 and Train accuracy of 0.23, Test loss: 3.03 and Test accuracy of 0.269
Iteration 12544: with minibatch training loss = 3.02 and accuracy of 0.25
Iteration 12672: with minibatch training loss = 3.32 and accuracy of 0.23
Iteration 12800: with minibatch training loss = 2.83 and accuracy of 0.24
Epoch 33, Train loss: 3.11 and Train accuracy of 0.238, Test loss: 3.01 and Test accuracy of 0.272
Iteration 12928: with minibatch training loss = 3.2 and accuracy of 0.24
Iteration 13056: with minibatch training loss = 3.2 and accuracy of 0.26
Iteration 13184: with minibatch training loss = 2.98 and accuracy of 0.24
Epoch 34, Train loss: 3.08 and Train accuracy of 0.245, Test loss: 2.97 and Test accuracy of 0.274
Iteration 13312: with minibatch training loss = 3.08 and accuracy of 0.23
Iteration 13440: with minibatch training loss = 3.05 and accuracy of 0.27
Iteration 13568: with minibatch training loss = 2.96 and accuracy of 0.22
Epoch 35, Train loss: 3.04 and Train accuracy of 0.251, Test loss: 2.96 and Test accuracy of 0.281
Iteration 13696: with minibatch training loss = 3.07 and accuracy of 0.26
Iteration 13824: with minibatch training loss = 3.1 and accuracy of 0.24
Iteration 13952: with minibatch training loss = 3.23 and accuracy of 0.19
Epoch 36, Train loss: 3.02 and Train accuracy of 0.256, Test loss: 2.93 and Test accuracy of 0.287
Iteration 14080: with minibatch training loss = 2.86 and accuracy of 0.27
Iteration 14208: with minibatch training loss = 3 and accuracy of 0.27
Iteration 14336: with minibatch training loss = 3.1 and accuracy of 0.2
Iteration 14464: with minibatch training loss = 2.97 and accuracy of 0.25
Epoch 37, Train loss: 2.98 and Train accuracy of 0.263, Test loss: 2.91 and Test accuracy of 0.292
Iteration 14592: with minibatch training loss = 2.62 and accuracy of 0.35
Iteration 14720: with minibatch training loss = 2.9 and accuracy of 0.27
Iteration 14848: with minibatch training loss = 2.86 and accuracy of 0.25
Epoch 38, Train loss: 2.96 and Train accuracy of 0.267, Test loss: 2.89 and Test accuracy of 0.297
Iteration 14976: with minibatch training loss = 2.93 and accuracy of 0.27
Iteration 15104: with minibatch training loss = 2.93 and accuracy of 0.28
Iteration 15232: with minibatch training loss = 2.89 and accuracy of 0.3
Epoch 39, Train loss: 2.93 and Train accuracy of 0.276, Test loss: 2.91 and Test accuracy of 0.288
Iteration 15360: with minibatch training loss = 3.05 and accuracy of 0.3
Iteration 15488: with minibatch training loss = 3.07 and accuracy of 0.27
Iteration 15616: with minibatch training loss = 2.9 and accuracy of 0.31
Epoch 40, Train loss: 2.9 and Train accuracy of 0.277, Test loss: 2.86 and Test accuracy of 0.302
Iteration 15744: with minibatch training loss = 2.59 and accuracy of 0.33
Iteration 15872: with minibatch training loss = 3.05 and accuracy of 0.29
Iteration 16000: with minibatch training loss = 3.1 and accuracy of 0.23
Epoch 41, Train loss: 2.87 and Train accuracy of 0.283, Test loss: 2.82 and Test accuracy of 0.309
Iteration 16128: with minibatch training loss = 2.9 and accuracy of 0.28
Iteration 16256: with minibatch training loss = 2.86 and accuracy of 0.31
Iteration 16384: with minibatch training loss = 3.01 and accuracy of 0.23
Epoch 42, Train loss: 2.84 and Train accuracy of 0.289, Test loss: 2.82 and Test accuracy of 0.306
Iteration 16512: with minibatch training loss = 2.87 and accuracy of 0.25
Iteration 16640: with minibatch training loss = 2.7 and accuracy of 0.3
Iteration 16768: with minibatch training loss = 2.85 and accuracy of 0.25
Epoch 43, Train loss: 2.81 and Train accuracy of 0.296, Test loss: 2.79 and Test accuracy of 0.314
Iteration 16896: with minibatch training loss = 3.06 and accuracy of 0.25
Iteration 17024: with minibatch training loss = 2.98 and accuracy of 0.23
Iteration 17152: with minibatch training loss = 2.89 and accuracy of 0.24
Epoch 44, Train loss: 2.78 and Train accuracy of 0.301, Test loss: 2.77 and Test accuracy of 0.316
Iteration 17280: with minibatch training loss = 2.84 and accuracy of 0.31
Iteration 17408: with minibatch training loss = 2.51 and accuracy of 0.38
Iteration 17536: with minibatch training loss = 3.02 and accuracy of 0.24
Epoch 45, Train loss: 2.76 and Train accuracy of 0.305, Test loss: 2.79 and Test accuracy of 0.314
Iteration 17664: with minibatch training loss = 2.62 and accuracy of 0.31
Iteration 17792: with minibatch training loss = 2.81 and accuracy of 0.29
Iteration 17920: with minibatch training loss = 2.7 and accuracy of 0.24
Epoch 46, Train loss: 2.73 and Train accuracy of 0.31, Test loss: 2.75 and Test accuracy of 0.321
Iteration 18048: with minibatch training loss = 2.68 and accuracy of 0.38
Iteration 18176: with minibatch training loss = 2.75 and accuracy of 0.3
Iteration 18304: with minibatch training loss = 2.95 and accuracy of 0.23
Epoch 47, Train loss: 2.7 and Train accuracy of 0.316, Test loss: 2.7 and Test accuracy of 0.328
Iteration 18432: with minibatch training loss = 2.81 and accuracy of 0.3
Iteration 18560: with minibatch training loss = 2.87 and accuracy of 0.3
Iteration 18688: with minibatch training loss = 2.79 and accuracy of 0.27
Epoch 48, Train loss: 2.67 and Train accuracy of 0.323, Test loss: 2.72 and Test accuracy of 0.328
Iteration 18816: with minibatch training loss = 2.3 and accuracy of 0.39
Iteration 18944: with minibatch training loss = 2.83 and accuracy of 0.28
Iteration 19072: with minibatch training loss = 2.58 and accuracy of 0.35
Epoch 49, Train loss: 2.65 and Train accuracy of 0.325, Test loss: 2.69 and Test accuracy of 0.332
Iteration 19200: with minibatch training loss = 2.76 and accuracy of 0.27
Iteration 19328: with minibatch training loss = 2.57 and accuracy of 0.37
Iteration 19456: with minibatch training loss = 2.67 and accuracy of 0.32
Epoch 50, Train loss: 2.62 and Train accuracy of 0.333, Test loss: 2.72 and Test accuracy of 0.329
Iteration 19584: with minibatch training loss = 2.66 and accuracy of 0.33
Iteration 19712: with minibatch training loss = 2.57 and accuracy of 0.35
Iteration 19840: with minibatch training loss = 2.29 and accuracy of 0.38
Epoch 51, Train loss: 2.58 and Train accuracy of 0.339, Test loss: 2.68 and Test accuracy of 0.334
Iteration 19968: with minibatch training loss = 2.5 and accuracy of 0.38
Iteration 20096: with minibatch training loss = 2.64 and accuracy of 0.31
Iteration 20224: with minibatch training loss = 2.95 and accuracy of 0.27
Epoch 52, Train loss: 2.56 and Train accuracy of 0.344, Test loss: 2.69 and Test accuracy of 0.336
Iteration 20352: with minibatch training loss = 2.53 and accuracy of 0.35
Iteration 20480: with minibatch training loss = 2.53 and accuracy of 0.3
Iteration 20608: with minibatch training loss = 2.69 and accuracy of 0.34
Epoch 53, Train loss: 2.53 and Train accuracy of 0.348, Test loss: 2.63 and Test accuracy of 0.344
Iteration 20736: with minibatch training loss = 2.29 and accuracy of 0.48
Iteration 20864: with minibatch training loss = 2.3 and accuracy of 0.41
Iteration 20992: with minibatch training loss = 2.71 and accuracy of 0.31
Epoch 54, Train loss: 2.51 and Train accuracy of 0.354, Test loss: 2.63 and Test accuracy of 0.346
Iteration 21120: with minibatch training loss = 2.65 and accuracy of 0.3
Iteration 21248: with minibatch training loss = 2.51 and accuracy of 0.33
Iteration 21376: with minibatch training loss = 2.28 and accuracy of 0.39
Iteration 21504: with minibatch training loss = 2.41 and accuracy of 0.33
Epoch 55, Train loss: 2.48 and Train accuracy of 0.36, Test loss: 2.65 and Test accuracy of 0.342
Iteration 21632: with minibatch training loss = 2.49 and accuracy of 0.34
Iteration 21760: with minibatch training loss = 2.37 and accuracy of 0.38
Iteration 21888: with minibatch training loss = 2.19 and accuracy of 0.48
Epoch 56, Train loss: 2.45 and Train accuracy of 0.365, Test loss: 2.6 and Test accuracy of 0.353
Iteration 22016: with minibatch training loss = 2.14 and accuracy of 0.42
Iteration 22144: with minibatch training loss = 2.28 and accuracy of 0.4
Iteration 22272: with minibatch training loss = 2.28 and accuracy of 0.37
Epoch 57, Train loss: 2.42 and Train accuracy of 0.372, Test loss: 2.57 and Test accuracy of 0.356
Iteration 22400: with minibatch training loss = 2.49 and accuracy of 0.32
Iteration 22528: with minibatch training loss = 2.42 and accuracy of 0.36
Iteration 22656: with minibatch training loss = 2.54 and accuracy of 0.32
Epoch 58, Train loss: 2.4 and Train accuracy of 0.373, Test loss: 2.58 and Test accuracy of 0.354
Iteration 22784: with minibatch training loss = 2.62 and accuracy of 0.32
Iteration 22912: with minibatch training loss = 2.24 and accuracy of 0.38
Iteration 23040: with minibatch training loss = 2.2 and accuracy of 0.42
Epoch 59, Train loss: 2.37 and Train accuracy of 0.38, Test loss: 2.58 and Test accuracy of 0.363
Iteration 23168: with minibatch training loss = 2.34 and accuracy of 0.31
Iteration 23296: with minibatch training loss = 2.36 and accuracy of 0.42
Iteration 23424: with minibatch training loss = 2.22 and accuracy of 0.4
Epoch 60, Train loss: 2.34 and Train accuracy of 0.387, Test loss: 2.58 and Test accuracy of 0.356
Iteration 23552: with minibatch training loss = 2.31 and accuracy of 0.45
Iteration 23680: with minibatch training loss = 2.16 and accuracy of 0.34
Iteration 23808: with minibatch training loss = 2.29 and accuracy of 0.45
Epoch 61, Train loss: 2.32 and Train accuracy of 0.393, Test loss: 2.55 and Test accuracy of 0.363
Iteration 23936: with minibatch training loss = 2.46 and accuracy of 0.37
Iteration 24064: with minibatch training loss = 2.3 and accuracy of 0.39
Iteration 24192: with minibatch training loss = 2.46 and accuracy of 0.36
Epoch 62, Train loss: 2.29 and Train accuracy of 0.396, Test loss: 2.54 and Test accuracy of 0.364
Iteration 24320: with minibatch training loss = 2.24 and accuracy of 0.44
Iteration 24448: with minibatch training loss = 2.23 and accuracy of 0.41
Iteration 24576: with minibatch training loss = 2.35 and accuracy of 0.35
Epoch 63, Train loss: 2.26 and Train accuracy of 0.404, Test loss: 2.57 and Test accuracy of 0.364
Iteration 24704: with minibatch training loss = 2.22 and accuracy of 0.41
Iteration 24832: with minibatch training loss = 2.11 and accuracy of 0.41
Iteration 24960: with minibatch training loss = 2.24 and accuracy of 0.43
Epoch 64, Train loss: 2.23 and Train accuracy of 0.41, Test loss: 2.53 and Test accuracy of 0.37
Iteration 25088: with minibatch training loss = 2.33 and accuracy of 0.41
Iteration 25216: with minibatch training loss = 2.32 and accuracy of 0.37
Iteration 25344: with minibatch training loss = 2.44 and accuracy of 0.35
Epoch 65, Train loss: 2.2 and Train accuracy of 0.414, Test loss: 2.53 and Test accuracy of 0.372
Iteration 25472: with minibatch training loss = 2.26 and accuracy of 0.42
Iteration 25600: with minibatch training loss = 1.98 and accuracy of 0.41
Iteration 25728: with minibatch training loss = 2.16 and accuracy of 0.44
Epoch 66, Train loss: 2.17 and Train accuracy of 0.421, Test loss: 2.52 and Test accuracy of 0.374
Iteration 25856: with minibatch training loss = 2.11 and accuracy of 0.45
Iteration 25984: with minibatch training loss = 1.9 and accuracy of 0.46
Iteration 26112: with minibatch training loss = 2.13 and accuracy of 0.43
Epoch 67, Train loss: 2.15 and Train accuracy of 0.425, Test loss: 2.55 and Test accuracy of 0.369
Iteration 26240: with minibatch training loss = 2.13 and accuracy of 0.45
Iteration 26368: with minibatch training loss = 1.87 and accuracy of 0.52
Iteration 26496: with minibatch training loss = 2.25 and accuracy of 0.35
Epoch 68, Train loss: 2.12 and Train accuracy of 0.433, Test loss: 2.56 and Test accuracy of 0.371
Iteration 26624: with minibatch training loss = 2.15 and accuracy of 0.45
Iteration 26752: with minibatch training loss = 2.06 and accuracy of 0.44
Iteration 26880: with minibatch training loss = 2.31 and accuracy of 0.39
Epoch 69, Train loss: 2.1 and Train accuracy of 0.435, Test loss: 2.56 and Test accuracy of 0.371
Iteration 27008: with minibatch training loss = 1.84 and accuracy of 0.49
Iteration 27136: with minibatch training loss = 2.35 and accuracy of 0.4
Iteration 27264: with minibatch training loss = 1.93 and accuracy of 0.51
Epoch 70, Train loss: 2.07 and Train accuracy of 0.442, Test loss: 2.53 and Test accuracy of 0.378
Iteration 27392: with minibatch training loss = 2.37 and accuracy of 0.42
Iteration 27520: with minibatch training loss = 2.17 and accuracy of 0.41
Iteration 27648: with minibatch training loss = 2.03 and accuracy of 0.45
Epoch 71, Train loss: 2.05 and Train accuracy of 0.446, Test loss: 2.53 and Test accuracy of 0.382
Iteration 27776: with minibatch training loss = 2.14 and accuracy of 0.38
Iteration 27904: with minibatch training loss = 2.05 and accuracy of 0.45
Iteration 28032: with minibatch training loss = 2.2 and accuracy of 0.46
Epoch 72, Train loss: 2.01 and Train accuracy of 0.454, Test loss: 2.56 and Test accuracy of 0.374
Iteration 28160: with minibatch training loss = 1.93 and accuracy of 0.45
Iteration 28288: with minibatch training loss = 1.87 and accuracy of 0.46
Iteration 28416: with minibatch training loss = 2.18 and accuracy of 0.38
Epoch 73, Train loss: 1.98 and Train accuracy of 0.46, Test loss: 2.53 and Test accuracy of 0.383
Iteration 28544: with minibatch training loss = 2.26 and accuracy of 0.4
Iteration 28672: with minibatch training loss = 1.77 and accuracy of 0.47
Iteration 28800: with minibatch training loss = 1.99 and accuracy of 0.48
Iteration 28928: with minibatch training loss = 2.03 and accuracy of 0.45
Epoch 74, Train loss: 1.96 and Train accuracy of 0.466, Test loss: 2.56 and Test accuracy of 0.38
Iteration 29056: with minibatch training loss = 1.87 and accuracy of 0.52
Iteration 29184: with minibatch training loss = 1.8 and accuracy of 0.48
Iteration 29312: with minibatch training loss = 2.04 and accuracy of 0.42
Epoch 75, Train loss: 1.93 and Train accuracy of 0.474, Test loss: 2.52 and Test accuracy of 0.384
Iteration 29440: with minibatch training loss = 1.67 and accuracy of 0.54
Iteration 29568: with minibatch training loss = 1.82 and accuracy of 0.52
Iteration 29696: with minibatch training loss = 2.01 and accuracy of 0.42
Epoch 76, Train loss: 1.89 and Train accuracy of 0.481, Test loss: 2.57 and Test accuracy of 0.383
Iteration 29824: with minibatch training loss = 2.24 and accuracy of 0.45
Iteration 29952: with minibatch training loss = 1.85 and accuracy of 0.49
Iteration 30080: with minibatch training loss = 1.92 and accuracy of 0.49
Epoch 77, Train loss: 1.88 and Train accuracy of 0.486, Test loss: 2.53 and Test accuracy of 0.385
Iteration 30208: with minibatch training loss = 2.06 and accuracy of 0.43
Iteration 30336: with minibatch training loss = 1.87 and accuracy of 0.48
Iteration 30464: with minibatch training loss = 1.93 and accuracy of 0.45
Epoch 78, Train loss: 1.85 and Train accuracy of 0.488, Test loss: 2.52 and Test accuracy of 0.389
Iteration 30592: with minibatch training loss = 2.02 and accuracy of 0.46
Iteration 30720: with minibatch training loss = 1.78 and accuracy of 0.48
Iteration 30848: with minibatch training loss = 1.87 and accuracy of 0.48
Epoch 79, Train loss: 1.82 and Train accuracy of 0.495, Test loss: 2.53 and Test accuracy of 0.389
Iteration 30976: with minibatch training loss = 1.66 and accuracy of 0.56
Iteration 31104: with minibatch training loss = 1.54 and accuracy of 0.54
Iteration 31232: with minibatch training loss = 1.87 and accuracy of 0.45
Epoch 80, Train loss: 1.8 and Train accuracy of 0.502, Test loss: 2.52 and Test accuracy of 0.395
Iteration 31360: with minibatch training loss = 1.85 and accuracy of 0.48
Iteration 31488: with minibatch training loss = 1.55 and accuracy of 0.56
Iteration 31616: with minibatch training loss = 1.46 and accuracy of 0.58
Epoch 81, Train loss: 1.76 and Train accuracy of 0.509, Test loss: 2.58 and Test accuracy of 0.387
Iteration 31744: with minibatch training loss = 1.67 and accuracy of 0.52
Iteration 31872: with minibatch training loss = 1.88 and accuracy of 0.5
Iteration 32000: with minibatch training loss = 1.86 and accuracy of 0.48
Epoch 82, Train loss: 1.74 and Train accuracy of 0.515, Test loss: 2.54 and Test accuracy of 0.393
Iteration 32128: with minibatch training loss = 1.53 and accuracy of 0.53
Iteration 32256: with minibatch training loss = 1.74 and accuracy of 0.52
Iteration 32384: with minibatch training loss = 1.94 and accuracy of 0.5
Epoch 83, Train loss: 1.7 and Train accuracy of 0.524, Test loss: 2.56 and Test accuracy of 0.388
Iteration 32512: with minibatch training loss = 1.75 and accuracy of 0.52
Iteration 32640: with minibatch training loss = 1.78 and accuracy of 0.49
Iteration 32768: with minibatch training loss = 1.77 and accuracy of 0.55
Epoch 84, Train loss: 1.68 and Train accuracy of 0.527, Test loss: 2.61 and Test accuracy of 0.39
Iteration 32896: with minibatch training loss = 1.72 and accuracy of 0.5
Iteration 33024: with minibatch training loss = 1.83 and accuracy of 0.45
Iteration 33152: with minibatch training loss = 1.78 and accuracy of 0.52
Epoch 85, Train loss: 1.66 and Train accuracy of 0.531, Test loss: 2.63 and Test accuracy of 0.386
Iteration 33280: with minibatch training loss = 1.68 and accuracy of 0.52
Iteration 33408: with minibatch training loss = 1.71 and accuracy of 0.47
Iteration 33536: with minibatch training loss = 1.66 and accuracy of 0.5
Epoch 86, Train loss: 1.62 and Train accuracy of 0.541, Test loss: 2.57 and Test accuracy of 0.395
Iteration 33664: with minibatch training loss = 1.7 and accuracy of 0.52
Iteration 33792: with minibatch training loss = 1.59 and accuracy of 0.59
Iteration 33920: with minibatch training loss = 1.53 and accuracy of 0.55
Epoch 87, Train loss: 1.59 and Train accuracy of 0.553, Test loss: 2.6 and Test accuracy of 0.395
Iteration 34048: with minibatch training loss = 1.27 and accuracy of 0.65
Iteration 34176: with minibatch training loss = 1.61 and accuracy of 0.53
Iteration 34304: with minibatch training loss = 1.51 and accuracy of 0.56
Epoch 88, Train loss: 1.57 and Train accuracy of 0.554, Test loss: 2.6 and Test accuracy of 0.395
Iteration 34432: with minibatch training loss = 1.37 and accuracy of 0.62
Iteration 34560: with minibatch training loss = 1.76 and accuracy of 0.51
Iteration 34688: with minibatch training loss = 1.56 and accuracy of 0.57
Epoch 89, Train loss: 1.55 and Train accuracy of 0.559, Test loss: 2.62 and Test accuracy of 0.396
Iteration 34816: with minibatch training loss = 1.36 and accuracy of 0.67
Iteration 34944: with minibatch training loss = 1.63 and accuracy of 0.51
Iteration 35072: with minibatch training loss = 1.35 and accuracy of 0.58
Epoch 90, Train loss: 1.51 and Train accuracy of 0.567, Test loss: 2.6 and Test accuracy of 0.401
Iteration 35200: with minibatch training loss = 1.36 and accuracy of 0.6
Iteration 35328: with minibatch training loss = 1.64 and accuracy of 0.52
Iteration 35456: with minibatch training loss = 1.48 and accuracy of 0.58
Epoch 91, Train loss: 1.49 and Train accuracy of 0.572, Test loss: 2.64 and Test accuracy of 0.391
Iteration 35584: with minibatch training loss = 1.5 and accuracy of 0.59
Iteration 35712: with minibatch training loss = 1.48 and accuracy of 0.58
Iteration 35840: with minibatch training loss = 1.23 and accuracy of 0.62
Iteration 35968: with minibatch training loss = 1.38 and accuracy of 0.61
Epoch 92, Train loss: 1.45 and Train accuracy of 0.579, Test loss: 2.67 and Test accuracy of 0.398
Iteration 36096: with minibatch training loss = 1.3 and accuracy of 0.62
Iteration 36224: with minibatch training loss = 1.37 and accuracy of 0.59
Iteration 36352: with minibatch training loss = 1.49 and accuracy of 0.59
Epoch 93, Train loss: 1.44 and Train accuracy of 0.584, Test loss: 2.61 and Test accuracy of 0.404
Iteration 36480: with minibatch training loss = 1.36 and accuracy of 0.55
Iteration 36608: with minibatch training loss = 1.48 and accuracy of 0.59
Iteration 36736: with minibatch training loss = 1.34 and accuracy of 0.55
Epoch 94, Train loss: 1.41 and Train accuracy of 0.589, Test loss: 2.59 and Test accuracy of 0.402
Iteration 36864: with minibatch training loss = 1.31 and accuracy of 0.59
Iteration 36992: with minibatch training loss = 1.31 and accuracy of 0.59
Iteration 37120: with minibatch training loss = 1.37 and accuracy of 0.55
Epoch 95, Train loss: 1.38 and Train accuracy of 0.599, Test loss: 2.63 and Test accuracy of 0.4
Iteration 37248: with minibatch training loss = 1.31 and accuracy of 0.63
Iteration 37376: with minibatch training loss = 1.37 and accuracy of 0.61
Iteration 37504: with minibatch training loss = 1.18 and accuracy of 0.69
Epoch 96, Train loss: 1.35 and Train accuracy of 0.605, Test loss: 2.68 and Test accuracy of 0.398
Iteration 37632: with minibatch training loss = 1.31 and accuracy of 0.63
Iteration 37760: with minibatch training loss = 1.43 and accuracy of 0.62
Iteration 37888: with minibatch training loss = 0.972 and accuracy of 0.72
Epoch 97, Train loss: 1.33 and Train accuracy of 0.611, Test loss: 2.69 and Test accuracy of 0.4
Iteration 38016: with minibatch training loss = 0.986 and accuracy of 0.7
Iteration 38144: with minibatch training loss = 1.22 and accuracy of 0.59
Iteration 38272: with minibatch training loss = 1.43 and accuracy of 0.6
Epoch 98, Train loss: 1.3 and Train accuracy of 0.616, Test loss: 2.76 and Test accuracy of 0.396
Iteration 38400: with minibatch training loss = 1.25 and accuracy of 0.63
Iteration 38528: with minibatch training loss = 1.23 and accuracy of 0.64
Iteration 38656: with minibatch training loss = 1.35 and accuracy of 0.62
Epoch 99, Train loss: 1.28 and Train accuracy of 0.622, Test loss: 2.68 and Test accuracy of 0.399
Iteration 38784: with minibatch training loss = 1.5 and accuracy of 0.55
Iteration 38912: with minibatch training loss = 1.31 and accuracy of 0.59
Iteration 39040: with minibatch training loss = 1.26 and accuracy of 0.64
Epoch 100, Train loss: 1.26 and Train accuracy of 0.626, Test loss: 2.71 and Test accuracy of 0.401
Iteration 39168: with minibatch training loss = 1.1 and accuracy of 0.7
Iteration 39296: with minibatch training loss = 1.33 and accuracy of 0.59
Iteration 39424: with minibatch training loss = 1.27 and accuracy of 0.64
Epoch 101, Train loss: 1.24 and Train accuracy of 0.635, Test loss: 2.8 and Test accuracy of 0.394
Iteration 39552: with minibatch training loss = 1.17 and accuracy of 0.62
Iteration 39680: with minibatch training loss = 1.24 and accuracy of 0.66
Iteration 39808: with minibatch training loss = 1.36 and accuracy of 0.61
Epoch 102, Train loss: 1.21 and Train accuracy of 0.643, Test loss: 2.73 and Test accuracy of 0.399
Iteration 39936: with minibatch training loss = 0.979 and accuracy of 0.67
Iteration 40064: with minibatch training loss = 1.38 and accuracy of 0.62
Iteration 40192: with minibatch training loss = 1.16 and accuracy of 0.65
Epoch 103, Train loss: 1.18 and Train accuracy of 0.651, Test loss: 2.72 and Test accuracy of 0.402
Iteration 40320: with minibatch training loss = 1.25 and accuracy of 0.63
Iteration 40448: with minibatch training loss = 1.15 and accuracy of 0.61
Iteration 40576: with minibatch training loss = 0.968 and accuracy of 0.74
Epoch 104, Train loss: 1.16 and Train accuracy of 0.652, Test loss: 2.73 and Test accuracy of 0.4
Iteration 40704: with minibatch training loss = 1.05 and accuracy of 0.71
Iteration 40832: with minibatch training loss = 1.12 and accuracy of 0.66
Iteration 40960: with minibatch training loss = 1.3 and accuracy of 0.56
Epoch 105, Train loss: 1.15 and Train accuracy of 0.655, Test loss: 2.76 and Test accuracy of 0.402
Iteration 41088: with minibatch training loss = 1.07 and accuracy of 0.67
Iteration 41216: with minibatch training loss = 1.01 and accuracy of 0.69
Iteration 41344: with minibatch training loss = 0.863 and accuracy of 0.73
Epoch 106, Train loss: 1.1 and Train accuracy of 0.668, Test loss: 2.79 and Test accuracy of 0.404
Iteration 41472: with minibatch training loss = 1.03 and accuracy of 0.7
Iteration 41600: with minibatch training loss = 1.1 and accuracy of 0.69
Iteration 41728: with minibatch training loss = 1.16 and accuracy of 0.62
Epoch 107, Train loss: 1.08 and Train accuracy of 0.675, Test loss: 2.76 and Test accuracy of 0.399
Iteration 41856: with minibatch training loss = 1.38 and accuracy of 0.57
Iteration 41984: with minibatch training loss = 1.26 and accuracy of 0.63
Iteration 42112: with minibatch training loss = 0.989 and accuracy of 0.63
Epoch 108, Train loss: 1.07 and Train accuracy of 0.675, Test loss: 2.81 and Test accuracy of 0.4
Iteration 42240: with minibatch training loss = 1.01 and accuracy of 0.66
Iteration 42368: with minibatch training loss = 0.928 and accuracy of 0.69
Iteration 42496: with minibatch training loss = 1.26 and accuracy of 0.6
Epoch 109, Train loss: 1.05 and Train accuracy of 0.683, Test loss: 2.75 and Test accuracy of 0.406
Iteration 42624: with minibatch training loss = 1.37 and accuracy of 0.57
Iteration 42752: with minibatch training loss = 1.15 and accuracy of 0.59
Iteration 42880: with minibatch training loss = 1.03 and accuracy of 0.68
Iteration 43008: with minibatch training loss = 1.09 and accuracy of 0.69
Epoch 110, Train loss: 1.03 and Train accuracy of 0.69, Test loss: 2.79 and Test accuracy of 0.398
Iteration 43136: with minibatch training loss = 1.18 and accuracy of 0.63
Iteration 43264: with minibatch training loss = 1.07 and accuracy of 0.72
Iteration 43392: with minibatch training loss = 1.04 and accuracy of 0.68
Epoch 111, Train loss: 1 and Train accuracy of 0.697, Test loss: 2.82 and Test accuracy of 0.401
Iteration 43520: with minibatch training loss = 0.939 and accuracy of 0.7
Iteration 43648: with minibatch training loss = 0.971 and accuracy of 0.79
Iteration 43776: with minibatch training loss = 1.24 and accuracy of 0.63
Epoch 112, Train loss: 0.987 and Train accuracy of 0.699, Test loss: 2.8 and Test accuracy of 0.406
Iteration 43904: with minibatch training loss = 1.12 and accuracy of 0.69
Iteration 44032: with minibatch training loss = 0.918 and accuracy of 0.77
Iteration 44160: with minibatch training loss = 1.01 and accuracy of 0.7
Epoch 113, Train loss: 0.975 and Train accuracy of 0.705, Test loss: 2.83 and Test accuracy of 0.406
Iteration 44288: with minibatch training loss = 1.08 and accuracy of 0.72
Iteration 44416: with minibatch training loss = 1.01 and accuracy of 0.71
Iteration 44544: with minibatch training loss = 0.961 and accuracy of 0.68
Epoch 114, Train loss: 0.944 and Train accuracy of 0.712, Test loss: 2.81 and Test accuracy of 0.404
Iteration 44672: with minibatch training loss = 0.94 and accuracy of 0.72
Iteration 44800: with minibatch training loss = 1.18 and accuracy of 0.7
Iteration 44928: with minibatch training loss = 0.869 and accuracy of 0.72
Epoch 115, Train loss: 0.93 and Train accuracy of 0.718, Test loss: 2.82 and Test accuracy of 0.403
Iteration 45056: with minibatch training loss = 1.01 and accuracy of 0.73
Iteration 45184: with minibatch training loss = 0.735 and accuracy of 0.77
Iteration 45312: with minibatch training loss = 0.883 and accuracy of 0.75
Epoch 116, Train loss: 0.905 and Train accuracy of 0.723, Test loss: 2.85 and Test accuracy of 0.404
Iteration 45440: with minibatch training loss = 0.712 and accuracy of 0.77
Iteration 45568: with minibatch training loss = 1.03 and accuracy of 0.7
Iteration 45696: with minibatch training loss = 0.994 and accuracy of 0.73
Epoch 117, Train loss: 0.896 and Train accuracy of 0.727, Test loss: 2.86 and Test accuracy of 0.406
Iteration 45824: with minibatch training loss = 0.96 and accuracy of 0.73
Iteration 45952: with minibatch training loss = 0.848 and accuracy of 0.73
Iteration 46080: with minibatch training loss = 0.885 and accuracy of 0.77
Epoch 118, Train loss: 0.866 and Train accuracy of 0.734, Test loss: 2.97 and Test accuracy of 0.401
Iteration 46208: with minibatch training loss = 0.814 and accuracy of 0.74
Iteration 46336: with minibatch training loss = 0.662 and accuracy of 0.84
Iteration 46464: with minibatch training loss = 1.06 and accuracy of 0.73
Epoch 119, Train loss: 0.859 and Train accuracy of 0.738, Test loss: 2.91 and Test accuracy of 0.397
Iteration 46592: with minibatch training loss = 0.657 and accuracy of 0.8
Iteration 46720: with minibatch training loss = 0.889 and accuracy of 0.77
Iteration 46848: with minibatch training loss = 0.666 and accuracy of 0.81
Epoch 120, Train loss: 0.84 and Train accuracy of 0.743, Test loss: 2.91 and Test accuracy of 0.406
Iteration 46976: with minibatch training loss = 0.781 and accuracy of 0.8
Iteration 47104: with minibatch training loss = 0.649 and accuracy of 0.78
Iteration 47232: with minibatch training loss = 0.832 and accuracy of 0.77
Epoch 121, Train loss: 0.827 and Train accuracy of 0.745, Test loss: 3.04 and Test accuracy of 0.402
Iteration 47360: with minibatch training loss = 0.926 and accuracy of 0.73
Iteration 47488: with minibatch training loss = 0.676 and accuracy of 0.82
Iteration 47616: with minibatch training loss = 0.771 and accuracy of 0.77
Epoch 122, Train loss: 0.813 and Train accuracy of 0.748, Test loss: 2.92 and Test accuracy of 0.405
Iteration 47744: with minibatch training loss = 0.739 and accuracy of 0.74
Iteration 47872: with minibatch training loss = 0.785 and accuracy of 0.76
Iteration 48000: with minibatch training loss = 0.974 and accuracy of 0.71
Epoch 123, Train loss: 0.794 and Train accuracy of 0.755, Test loss: 2.94 and Test accuracy of 0.401
Iteration 48128: with minibatch training loss = 0.639 and accuracy of 0.82
Iteration 48256: with minibatch training loss = 0.79 and accuracy of 0.74
Iteration 48384: with minibatch training loss = 0.903 and accuracy of 0.74
Epoch 124, Train loss: 0.783 and Train accuracy of 0.758, Test loss: 2.99 and Test accuracy of 0.4
Iteration 48512: with minibatch training loss = 0.762 and accuracy of 0.77
Iteration 48640: with minibatch training loss = 0.735 and accuracy of 0.77
Iteration 48768: with minibatch training loss = 0.726 and accuracy of 0.8
Epoch 125, Train loss: 0.762 and Train accuracy of 0.763, Test loss: 3.01 and Test accuracy of 0.407
Iteration 48896: with minibatch training loss = 0.737 and accuracy of 0.79
Iteration 49024: with minibatch training loss = 0.866 and accuracy of 0.77
Iteration 49152: with minibatch training loss = 0.681 and accuracy of 0.81
Epoch 126, Train loss: 0.75 and Train accuracy of 0.767, Test loss: 2.93 and Test accuracy of 0.402
Iteration 49280: with minibatch training loss = 0.739 and accuracy of 0.8
Iteration 49408: with minibatch training loss = 0.844 and accuracy of 0.71
Iteration 49536: with minibatch training loss = 0.814 and accuracy of 0.75
Epoch 127, Train loss: 0.732 and Train accuracy of 0.773, Test loss: 2.95 and Test accuracy of 0.406
Iteration 49664: with minibatch training loss = 0.797 and accuracy of 0.77
Iteration 49792: with minibatch training loss = 0.771 and accuracy of 0.77
Iteration 49920: with minibatch training loss = 0.663 and accuracy of 0.8
Epoch 128, Train loss: 0.716 and Train accuracy of 0.777, Test loss: 3.06 and Test accuracy of 0.401
Iteration 50048: with minibatch training loss = 0.783 and accuracy of 0.77
Iteration 50176: with minibatch training loss = 0.611 and accuracy of 0.85
Iteration 50304: with minibatch training loss = 0.764 and accuracy of 0.77
Iteration 50432: with minibatch training loss = 0.556 and accuracy of 0.82
Epoch 129, Train loss: 0.696 and Train accuracy of 0.782, Test loss: 3.06 and Test accuracy of 0.407
Iteration 50560: with minibatch training loss = 0.601 and accuracy of 0.8
Iteration 50688: with minibatch training loss = 0.84 and accuracy of 0.74
Iteration 50816: with minibatch training loss = 0.692 and accuracy of 0.77
Epoch 130, Train loss: 0.698 and Train accuracy of 0.783, Test loss: 3.06 and Test accuracy of 0.401
Iteration 50944: with minibatch training loss = 0.751 and accuracy of 0.79
Iteration 51072: with minibatch training loss = 0.769 and accuracy of 0.73
Iteration 51200: with minibatch training loss = 0.684 and accuracy of 0.83
Epoch 131, Train loss: 0.681 and Train accuracy of 0.786, Test loss: 3.02 and Test accuracy of 0.402
Iteration 51328: with minibatch training loss = 0.766 and accuracy of 0.77
Iteration 51456: with minibatch training loss = 0.713 and accuracy of 0.8
Iteration 51584: with minibatch training loss = 0.622 and accuracy of 0.8
Epoch 132, Train loss: 0.674 and Train accuracy of 0.79, Test loss: 3.03 and Test accuracy of 0.401
Iteration 51712: with minibatch training loss = 0.65 and accuracy of 0.79
Iteration 51840: with minibatch training loss = 0.805 and accuracy of 0.75
Iteration 51968: with minibatch training loss = 0.707 and accuracy of 0.74
Epoch 133, Train loss: 0.656 and Train accuracy of 0.794, Test loss: 3.08 and Test accuracy of 0.402
Iteration 52096: with minibatch training loss = 0.509 and accuracy of 0.84
Iteration 52224: with minibatch training loss = 0.493 and accuracy of 0.85
Iteration 52352: with minibatch training loss = 0.73 and accuracy of 0.78
Epoch 134, Train loss: 0.648 and Train accuracy of 0.797, Test loss: 3.02 and Test accuracy of 0.4
Iteration 52480: with minibatch training loss = 0.873 and accuracy of 0.76
Iteration 52608: with minibatch training loss = 0.565 and accuracy of 0.82
Iteration 52736: with minibatch training loss = 0.641 and accuracy of 0.81
Epoch 135, Train loss: 0.63 and Train accuracy of 0.803, Test loss: 3.18 and Test accuracy of 0.396
Iteration 52864: with minibatch training loss = 0.586 and accuracy of 0.79
Iteration 52992: with minibatch training loss = 0.417 and accuracy of 0.84
Iteration 53120: with minibatch training loss = 0.627 and accuracy of 0.8
Epoch 136, Train loss: 0.622 and Train accuracy of 0.805, Test loss: 3.07 and Test accuracy of 0.404
Iteration 53248: with minibatch training loss = 0.601 and accuracy of 0.83
Iteration 53376: with minibatch training loss = 0.644 and accuracy of 0.81
Iteration 53504: with minibatch training loss = 0.598 and accuracy of 0.85
Epoch 137, Train loss: 0.612 and Train accuracy of 0.807, Test loss: 3.13 and Test accuracy of 0.403
Iteration 53632: with minibatch training loss = 0.592 and accuracy of 0.8
Iteration 53760: with minibatch training loss = 0.636 and accuracy of 0.77
Iteration 53888: with minibatch training loss = 0.627 and accuracy of 0.81
Epoch 138, Train loss: 0.599 and Train accuracy of 0.811, Test loss: 3.11 and Test accuracy of 0.401
Iteration 54016: with minibatch training loss = 0.58 and accuracy of 0.81
Iteration 54144: with minibatch training loss = 0.497 and accuracy of 0.88
Iteration 54272: with minibatch training loss = 0.647 and accuracy of 0.8
Epoch 139, Train loss: 0.589 and Train accuracy of 0.816, Test loss: 3.13 and Test accuracy of 0.403
Iteration 54400: with minibatch training loss = 0.527 and accuracy of 0.83
Iteration 54528: with minibatch training loss = 0.603 and accuracy of 0.8
Iteration 54656: with minibatch training loss = 0.601 and accuracy of 0.82
Epoch 140, Train loss: 0.576 and Train accuracy of 0.815, Test loss: 3.18 and Test accuracy of 0.401
Iteration 54784: with minibatch training loss = 0.663 and accuracy of 0.8
Iteration 54912: with minibatch training loss = 0.545 and accuracy of 0.83
Iteration 55040: with minibatch training loss = 0.554 and accuracy of 0.8
Epoch 141, Train loss: 0.57 and Train accuracy of 0.819, Test loss: 3.22 and Test accuracy of 0.404
Iteration 55168: with minibatch training loss = 0.61 and accuracy of 0.81
Iteration 55296: with minibatch training loss = 0.416 and accuracy of 0.86
Iteration 55424: with minibatch training loss = 0.502 and accuracy of 0.85
Epoch 142, Train loss: 0.559 and Train accuracy of 0.824, Test loss: 3.15 and Test accuracy of 0.402
Iteration 55552: with minibatch training loss = 0.508 and accuracy of 0.84
Iteration 55680: with minibatch training loss = 0.501 and accuracy of 0.83
Iteration 55808: with minibatch training loss = 0.695 and accuracy of 0.77
Epoch 143, Train loss: 0.549 and Train accuracy of 0.828, Test loss: 3.24 and Test accuracy of 0.406
Iteration 55936: with minibatch training loss = 0.455 and accuracy of 0.84
Iteration 56064: with minibatch training loss = 0.644 and accuracy of 0.83
Iteration 56192: with minibatch training loss = 0.638 and accuracy of 0.8
Epoch 144, Train loss: 0.542 and Train accuracy of 0.829, Test loss: 3.18 and Test accuracy of 0.401
Iteration 56320: with minibatch training loss = 0.587 and accuracy of 0.81
Iteration 56448: with minibatch training loss = 0.451 and accuracy of 0.83
Iteration 56576: with minibatch training loss = 0.476 and accuracy of 0.87
Epoch 145, Train loss: 0.536 and Train accuracy of 0.832, Test loss: 3.15 and Test accuracy of 0.403
Iteration 56704: with minibatch training loss = 0.418 and accuracy of 0.88
Iteration 56832: with minibatch training loss = 0.517 and accuracy of 0.87
Iteration 56960: with minibatch training loss = 0.446 and accuracy of 0.85
Epoch 146, Train loss: 0.519 and Train accuracy of 0.835, Test loss: 3.23 and Test accuracy of 0.397
Iteration 57088: with minibatch training loss = 0.393 and accuracy of 0.87
Iteration 57216: with minibatch training loss = 0.535 and accuracy of 0.84
Iteration 57344: with minibatch training loss = 0.551 and accuracy of 0.84
Iteration 57472: with minibatch training loss = 0.451 and accuracy of 0.83
Epoch 147, Train loss: 0.512 and Train accuracy of 0.839, Test loss: 3.29 and Test accuracy of 0.4
Iteration 57600: with minibatch training loss = 0.461 and accuracy of 0.84
Iteration 57728: with minibatch training loss = 0.518 and accuracy of 0.85
Iteration 57856: with minibatch training loss = 0.67 and accuracy of 0.78
Epoch 148, Train loss: 0.508 and Train accuracy of 0.839, Test loss: 3.21 and Test accuracy of 0.405
Iteration 57984: with minibatch training loss = 0.436 and accuracy of 0.85
Iteration 58112: with minibatch training loss = 0.548 and accuracy of 0.84
Iteration 58240: with minibatch training loss = 0.55 and accuracy of 0.84
Epoch 149, Train loss: 0.503 and Train accuracy of 0.84, Test loss: 3.22 and Test accuracy of 0.404
Iteration 58368: with minibatch training loss = 0.484 and accuracy of 0.87
Iteration 58496: with minibatch training loss = 0.475 and accuracy of 0.86
Iteration 58624: with minibatch training loss = 0.57 and accuracy of 0.82
Epoch 150, Train loss: 0.491 and Train accuracy of 0.844, Test loss: 3.31 and Test accuracy of 0.405
Iteration 58752: with minibatch training loss = 0.528 and accuracy of 0.84
Iteration 58880: with minibatch training loss = 0.488 and accuracy of 0.83
Iteration 59008: with minibatch training loss = 0.381 and accuracy of 0.89
Epoch 151, Train loss: 0.483 and Train accuracy of 0.846, Test loss: 3.33 and Test accuracy of 0.408
Iteration 59136: with minibatch training loss = 0.574 and accuracy of 0.8
Iteration 59264: with minibatch training loss = 0.465 and accuracy of 0.85
Iteration 59392: with minibatch training loss = 0.64 and accuracy of 0.84
Epoch 152, Train loss: 0.472 and Train accuracy of 0.849, Test loss: 3.25 and Test accuracy of 0.408
Iteration 59520: with minibatch training loss = 0.424 and accuracy of 0.88
Iteration 59648: with minibatch training loss = 0.491 and accuracy of 0.86
Iteration 59776: with minibatch training loss = 0.452 and accuracy of 0.84
Epoch 153, Train loss: 0.472 and Train accuracy of 0.85, Test loss: 3.37 and Test accuracy of 0.403
Iteration 59904: with minibatch training loss = 0.273 and accuracy of 0.92
Iteration 60032: with minibatch training loss = 0.443 and accuracy of 0.84
Iteration 60160: with minibatch training loss = 0.411 and accuracy of 0.87
Epoch 154, Train loss: 0.463 and Train accuracy of 0.853, Test loss: 3.3 and Test accuracy of 0.406
Iteration 60288: with minibatch training loss = 0.5 and accuracy of 0.84
Iteration 60416: with minibatch training loss = 0.314 and accuracy of 0.9
Iteration 60544: with minibatch training loss = 0.45 and accuracy of 0.83
Epoch 155, Train loss: 0.447 and Train accuracy of 0.859, Test loss: 3.3 and Test accuracy of 0.407
Iteration 60672: with minibatch training loss = 0.369 and accuracy of 0.89
Iteration 60800: with minibatch training loss = 0.35 and accuracy of 0.88
Iteration 60928: with minibatch training loss = 0.336 and accuracy of 0.88
Epoch 156, Train loss: 0.449 and Train accuracy of 0.858, Test loss: 3.45 and Test accuracy of 0.403
Iteration 61056: with minibatch training loss = 0.457 and accuracy of 0.8
Iteration 61184: with minibatch training loss = 0.521 and accuracy of 0.83
Iteration 61312: with minibatch training loss = 0.43 and accuracy of 0.83
Epoch 157, Train loss: 0.437 and Train accuracy of 0.862, Test loss: 3.37 and Test accuracy of 0.408
Iteration 61440: with minibatch training loss = 0.447 and accuracy of 0.86
Iteration 61568: with minibatch training loss = 0.45 and accuracy of 0.84
Iteration 61696: with minibatch training loss = 0.416 and accuracy of 0.85
Epoch 158, Train loss: 0.432 and Train accuracy of 0.862, Test loss: 3.34 and Test accuracy of 0.409
Iteration 61824: with minibatch training loss = 0.314 and accuracy of 0.9
Iteration 61952: with minibatch training loss = 0.352 and accuracy of 0.9
Iteration 62080: with minibatch training loss = 0.364 and accuracy of 0.86
Epoch 159, Train loss: 0.434 and Train accuracy of 0.864, Test loss: 3.3 and Test accuracy of 0.401
Iteration 62208: with minibatch training loss = 0.413 and accuracy of 0.88
Iteration 62336: with minibatch training loss = 0.334 and accuracy of 0.92
Iteration 62464: with minibatch training loss = 0.507 and accuracy of 0.88
Epoch 160, Train loss: 0.433 and Train accuracy of 0.862, Test loss: 3.32 and Test accuracy of 0.4
Iteration 62592: with minibatch training loss = 0.59 and accuracy of 0.84
Iteration 62720: with minibatch training loss = 0.325 and accuracy of 0.89
Iteration 62848: with minibatch training loss = 0.399 and accuracy of 0.88
Epoch 161, Train loss: 0.416 and Train accuracy of 0.867, Test loss: 3.43 and Test accuracy of 0.405
Iteration 62976: with minibatch training loss = 0.352 and accuracy of 0.91
Iteration 63104: with minibatch training loss = 0.507 and accuracy of 0.81
Iteration 63232: with minibatch training loss = 0.495 and accuracy of 0.82
Epoch 162, Train loss: 0.411 and Train accuracy of 0.868, Test loss: 3.35 and Test accuracy of 0.407
Iteration 63360: with minibatch training loss = 0.395 and accuracy of 0.85
Iteration 63488: with minibatch training loss = 0.357 and accuracy of 0.86
Iteration 63616: with minibatch training loss = 0.375 and accuracy of 0.89
Epoch 163, Train loss: 0.412 and Train accuracy of 0.867, Test loss: 3.35 and Test accuracy of 0.408
Iteration 63744: with minibatch training loss = 0.437 and accuracy of 0.84
Iteration 63872: with minibatch training loss = 0.315 and accuracy of 0.88
Iteration 64000: with minibatch training loss = 0.335 and accuracy of 0.89
Epoch 164, Train loss: 0.405 and Train accuracy of 0.871, Test loss: 3.37 and Test accuracy of 0.406
Iteration 64128: with minibatch training loss = 0.477 and accuracy of 0.8
Iteration 64256: with minibatch training loss = 0.456 and accuracy of 0.85
Iteration 64384: with minibatch training loss = 0.436 and accuracy of 0.84
Iteration 64512: with minibatch training loss = 0.358 and accuracy of 0.85
Epoch 165, Train loss: 0.398 and Train accuracy of 0.873, Test loss: 3.38 and Test accuracy of 0.409
Iteration 64640: with minibatch training loss = 0.275 and accuracy of 0.91
Iteration 64768: with minibatch training loss = 0.35 and accuracy of 0.89
Iteration 64896: with minibatch training loss = 0.428 and accuracy of 0.88
Epoch 166, Train loss: 0.398 and Train accuracy of 0.874, Test loss: 3.39 and Test accuracy of 0.405
Iteration 65024: with minibatch training loss = 0.494 and accuracy of 0.83
Iteration 65152: with minibatch training loss = 0.558 and accuracy of 0.83
Iteration 65280: with minibatch training loss = 0.34 and accuracy of 0.9
Epoch 167, Train loss: 0.393 and Train accuracy of 0.877, Test loss: 3.35 and Test accuracy of 0.409
Iteration 65408: with minibatch training loss = 0.406 and accuracy of 0.88
Iteration 65536: with minibatch training loss = 0.389 and accuracy of 0.9
Iteration 65664: with minibatch training loss = 0.332 and accuracy of 0.92
Epoch 168, Train loss: 0.375 and Train accuracy of 0.882, Test loss: 3.38 and Test accuracy of 0.403
Iteration 65792: with minibatch training loss = 0.301 and accuracy of 0.93
Iteration 65920: with minibatch training loss = 0.295 and accuracy of 0.89
Iteration 66048: with minibatch training loss = 0.399 and accuracy of 0.85
Epoch 169, Train loss: 0.376 and Train accuracy of 0.88, Test loss: 3.41 and Test accuracy of 0.406
Iteration 66176: with minibatch training loss = 0.326 and accuracy of 0.91
Iteration 66304: with minibatch training loss = 0.241 and accuracy of 0.92
Iteration 66432: with minibatch training loss = 0.388 and accuracy of 0.86
Epoch 170, Train loss: 0.375 and Train accuracy of 0.88, Test loss: 3.47 and Test accuracy of 0.405
Iteration 66560: with minibatch training loss = 0.398 and accuracy of 0.87
Iteration 66688: with minibatch training loss = 0.184 and accuracy of 0.95
Iteration 66816: with minibatch training loss = 0.352 and accuracy of 0.87
Epoch 171, Train loss: 0.369 and Train accuracy of 0.882, Test loss: 3.35 and Test accuracy of 0.403
Iteration 66944: with minibatch training loss = 0.402 and accuracy of 0.88
Iteration 67072: with minibatch training loss = 0.348 and accuracy of 0.87
Iteration 67200: with minibatch training loss = 0.366 and accuracy of 0.88
Epoch 172, Train loss: 0.361 and Train accuracy of 0.883, Test loss: 3.5 and Test accuracy of 0.406
Iteration 67328: with minibatch training loss = 0.381 and accuracy of 0.86
Iteration 67456: with minibatch training loss = 0.451 and accuracy of 0.88
Iteration 67584: with minibatch training loss = 0.302 and accuracy of 0.88
Epoch 173, Train loss: 0.361 and Train accuracy of 0.885, Test loss: 3.52 and Test accuracy of 0.408
Iteration 67712: with minibatch training loss = 0.323 and accuracy of 0.91
Iteration 67840: with minibatch training loss = 0.443 and accuracy of 0.84
Iteration 67968: with minibatch training loss = 0.346 and accuracy of 0.89
Epoch 174, Train loss: 0.347 and Train accuracy of 0.889, Test loss: 3.43 and Test accuracy of 0.409
Iteration 68096: with minibatch training loss = 0.355 and accuracy of 0.89
Iteration 68224: with minibatch training loss = 0.206 and accuracy of 0.95
Iteration 68352: with minibatch training loss = 0.282 and accuracy of 0.91
Epoch 175, Train loss: 0.355 and Train accuracy of 0.888, Test loss: 3.46 and Test accuracy of 0.408
Iteration 68480: with minibatch training loss = 0.323 and accuracy of 0.9
Iteration 68608: with minibatch training loss = 0.302 and accuracy of 0.91
Iteration 68736: with minibatch training loss = 0.284 and accuracy of 0.91
Epoch 176, Train loss: 0.339 and Train accuracy of 0.893, Test loss: 3.53 and Test accuracy of 0.409
Iteration 68864: with minibatch training loss = 0.327 and accuracy of 0.9
Iteration 68992: with minibatch training loss = 0.345 and accuracy of 0.88
Iteration 69120: with minibatch training loss = 0.386 and accuracy of 0.89
Epoch 177, Train loss: 0.347 and Train accuracy of 0.889, Test loss: 3.43 and Test accuracy of 0.407
Iteration 69248: with minibatch training loss = 0.379 and accuracy of 0.91
Iteration 69376: with minibatch training loss = 0.258 and accuracy of 0.91
Iteration 69504: with minibatch training loss = 0.412 and accuracy of 0.87
Epoch 178, Train loss: 0.337 and Train accuracy of 0.894, Test loss: 3.59 and Test accuracy of 0.407
Iteration 69632: with minibatch training loss = 0.346 and accuracy of 0.88
Iteration 69760: with minibatch training loss = 0.225 and accuracy of 0.93
Iteration 69888: with minibatch training loss = 0.436 and accuracy of 0.88
Epoch 179, Train loss: 0.335 and Train accuracy of 0.893, Test loss: 3.49 and Test accuracy of 0.412
Iteration 70016: with minibatch training loss = 0.292 and accuracy of 0.91
Iteration 70144: with minibatch training loss = 0.358 and accuracy of 0.88
Iteration 70272: with minibatch training loss = 0.556 and accuracy of 0.86
Epoch 180, Train loss: 0.336 and Train accuracy of 0.893, Test loss: 3.46 and Test accuracy of 0.407
Iteration 70400: with minibatch training loss = 0.365 and accuracy of 0.88
Iteration 70528: with minibatch training loss = 0.341 and accuracy of 0.9
Iteration 70656: with minibatch training loss = 0.246 and accuracy of 0.91
Epoch 181, Train loss: 0.324 and Train accuracy of 0.897, Test loss: 3.59 and Test accuracy of 0.416
Iteration 70784: with minibatch training loss = 0.359 and accuracy of 0.9
Iteration 70912: with minibatch training loss = 0.461 and accuracy of 0.89
Iteration 71040: with minibatch training loss = 0.405 and accuracy of 0.91
Epoch 182, Train loss: 0.321 and Train accuracy of 0.896, Test loss: 3.57 and Test accuracy of 0.406
Iteration 71168: with minibatch training loss = 0.26 and accuracy of 0.94
Iteration 71296: with minibatch training loss = 0.249 and accuracy of 0.93
Iteration 71424: with minibatch training loss = 0.269 and accuracy of 0.89
Iteration 71552: with minibatch training loss = 0.237 and accuracy of 0.9
Epoch 183, Train loss: 0.321 and Train accuracy of 0.897, Test loss: 3.54 and Test accuracy of 0.408
Iteration 71680: with minibatch training loss = 0.29 and accuracy of 0.91
Iteration 71808: with minibatch training loss = 0.287 and accuracy of 0.88
Iteration 71936: with minibatch training loss = 0.205 and accuracy of 0.93
Epoch 184, Train loss: 0.312 and Train accuracy of 0.902, Test loss: 3.49 and Test accuracy of 0.408
Iteration 72064: with minibatch training loss = 0.345 and accuracy of 0.86
Iteration 72192: with minibatch training loss = 0.308 and accuracy of 0.9
Iteration 72320: with minibatch training loss = 0.433 and accuracy of 0.87
Epoch 185, Train loss: 0.309 and Train accuracy of 0.901, Test loss: 3.51 and Test accuracy of 0.406
Iteration 72448: with minibatch training loss = 0.372 and accuracy of 0.88
Iteration 72576: with minibatch training loss = 0.247 and accuracy of 0.91
Iteration 72704: with minibatch training loss = 0.393 and accuracy of 0.89
Epoch 186, Train loss: 0.308 and Train accuracy of 0.9, Test loss: 3.52 and Test accuracy of 0.411
Iteration 72832: with minibatch training loss = 0.243 and accuracy of 0.93
Iteration 72960: with minibatch training loss = 0.406 and accuracy of 0.89
Iteration 73088: with minibatch training loss = 0.293 and accuracy of 0.91
Epoch 187, Train loss: 0.302 and Train accuracy of 0.904, Test loss: 3.52 and Test accuracy of 0.406
Iteration 73216: with minibatch training loss = 0.275 and accuracy of 0.91
Iteration 73344: with minibatch training loss = 0.358 and accuracy of 0.9
Iteration 73472: with minibatch training loss = 0.304 and accuracy of 0.88
Epoch 188, Train loss: 0.3 and Train accuracy of 0.904, Test loss: 3.56 and Test accuracy of 0.409
Iteration 73600: with minibatch training loss = 0.341 and accuracy of 0.89
Iteration 73728: with minibatch training loss = 0.324 and accuracy of 0.87
Iteration 73856: with minibatch training loss = 0.409 and accuracy of 0.9
Epoch 189, Train loss: 0.292 and Train accuracy of 0.906, Test loss: 3.56 and Test accuracy of 0.411
Iteration 73984: with minibatch training loss = 0.221 and accuracy of 0.92
Iteration 74112: with minibatch training loss = 0.32 and accuracy of 0.88
Iteration 74240: with minibatch training loss = 0.321 and accuracy of 0.9
Epoch 190, Train loss: 0.295 and Train accuracy of 0.906, Test loss: 3.59 and Test accuracy of 0.409
Iteration 74368: with minibatch training loss = 0.0872 and accuracy of 0.97
Iteration 74496: with minibatch training loss = 0.474 and accuracy of 0.84
Iteration 74624: with minibatch training loss = 0.338 and accuracy of 0.89
Epoch 191, Train loss: 0.284 and Train accuracy of 0.91, Test loss: 3.6 and Test accuracy of 0.412
Iteration 74752: with minibatch training loss = 0.26 and accuracy of 0.94
Iteration 74880: with minibatch training loss = 0.291 and accuracy of 0.94
Iteration 75008: with minibatch training loss = 0.303 and accuracy of 0.91
Epoch 192, Train loss: 0.288 and Train accuracy of 0.907, Test loss: 3.59 and Test accuracy of 0.408
Iteration 75136: with minibatch training loss = 0.353 and accuracy of 0.9
Iteration 75264: with minibatch training loss = 0.252 and accuracy of 0.92
Iteration 75392: with minibatch training loss = 0.278 and accuracy of 0.94
Epoch 193, Train loss: 0.281 and Train accuracy of 0.912, Test loss: 3.57 and Test accuracy of 0.411
Iteration 75520: with minibatch training loss = 0.325 and accuracy of 0.89
Iteration 75648: with minibatch training loss = 0.211 and accuracy of 0.91
Iteration 75776: with minibatch training loss = 0.161 and accuracy of 0.95
Epoch 194, Train loss: 0.274 and Train accuracy of 0.914, Test loss: 3.63 and Test accuracy of 0.409
Iteration 75904: with minibatch training loss = 0.284 and accuracy of 0.91
Iteration 76032: with minibatch training loss = 0.23 and accuracy of 0.95
Iteration 76160: with minibatch training loss = 0.246 and accuracy of 0.9
Epoch 195, Train loss: 0.277 and Train accuracy of 0.914, Test loss: 3.63 and Test accuracy of 0.412
Iteration 76288: with minibatch training loss = 0.25 and accuracy of 0.9
Iteration 76416: with minibatch training loss = 0.316 and accuracy of 0.88
Iteration 76544: with minibatch training loss = 0.244 and accuracy of 0.95
Epoch 196, Train loss: 0.272 and Train accuracy of 0.913, Test loss: 3.68 and Test accuracy of 0.411
Iteration 76672: with minibatch training loss = 0.303 and accuracy of 0.89
Iteration 76800: with minibatch training loss = 0.255 and accuracy of 0.93
Iteration 76928: with minibatch training loss = 0.204 and accuracy of 0.92
Epoch 197, Train loss: 0.274 and Train accuracy of 0.913, Test loss: 3.64 and Test accuracy of 0.411
Iteration 77056: with minibatch training loss = 0.367 and accuracy of 0.88
Iteration 77184: with minibatch training loss = 0.299 and accuracy of 0.92
Iteration 77312: with minibatch training loss = 0.307 and accuracy of 0.91
Epoch 198, Train loss: 0.267 and Train accuracy of 0.916, Test loss: 3.56 and Test accuracy of 0.409
Iteration 77440: with minibatch training loss = 0.211 and accuracy of 0.91
Iteration 77568: with minibatch training loss = 0.331 and accuracy of 0.93
Iteration 77696: with minibatch training loss = 0.171 and accuracy of 0.95
Epoch 199, Train loss: 0.267 and Train accuracy of 0.914, Test loss: 3.64 and Test accuracy of 0.41
Iteration 77824: with minibatch training loss = 0.345 and accuracy of 0.91
Iteration 77952: with minibatch training loss = 0.298 and accuracy of 0.91
Iteration 78080: with minibatch training loss = 0.152 and accuracy of 0.96
Epoch 200, Train loss: 0.263 and Train accuracy of 0.917, Test loss: 3.7 and Test accuracy of 0.407
1:48:29.517264